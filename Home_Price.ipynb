{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younesabdolmalaky/Car-price/blob/main/Home_Price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1EnzrEj7fcg",
        "outputId": "cd7fb9b1-0d63-49f8-b4d5-a40a8dfd9fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Downloading house-prices-advanced-regression-techniques.zip to /content\n",
            "  0% 0.00/199k [00:00<?, ?B/s]\n",
            "100% 199k/199k [00:00<00:00, 31.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0YFtAjS7loG",
        "outputId": "b9ad3b21-db2e-4cc7-de80-5d95bb446c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/house-prices-advanced-regression-techniques.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! unzip /content/house-prices-advanced-regression-techniques.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oFQKzXs74jP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder , MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5479dZyA8JUc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgVJ-MQB8OU_",
        "outputId": "5566eeaf-e357-4be8-f2f2-250016b8d414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 0\n",
              "MSSubClass         0\n",
              "MSZoning           0\n",
              "LotFrontage      259\n",
              "LotArea            0\n",
              "                ... \n",
              "MoSold             0\n",
              "YrSold             0\n",
              "SaleType           0\n",
              "SaleCondition      0\n",
              "SalePrice          0\n",
              "Length: 81, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "pd.options.display.max_rows = 10\n",
        "(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kxSdSGBsEKuA"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['Id','MiscFeature' , 'Fence' , 'PoolQC' ,'Alley' , 'FireplaceQu'],axis = 'columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sXPVHk8NJpkl"
      },
      "outputs": [],
      "source": [
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = df.select_dtypes(exclude=['float64' , 'int64']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KwRo7NH7J4Qx"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset = categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2SxZ5OJ2RH7D"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VFs0PPbvQbz6"
      },
      "outputs": [],
      "source": [
        "imputer = KNNImputer(n_neighbors=3)\n",
        "df = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5sIbjWPHAmC",
        "outputId": "acfaeb5b-3c15-4dc4-a1d0-d8d8013f67e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "df.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4IlYXxljqjYD"
      },
      "outputs": [],
      "source": [
        "df['Price'] = df['SalePrice']\n",
        "df = df.drop(\"SalePrice\", axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YQ5hoAX0ZfSg"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "data = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "u-JsoLCp3UAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_tQa1Rr4a6JA"
      },
      "outputs": [],
      "source": [
        "y = data[: ,df.columns.get_loc(\"Price\") ]\n",
        "X = np.delete(data, df.columns.get_loc(\"Price\") , axis=1)\n",
        "y=y.astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Qy9qreWdcgBw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7LNt5dxyidm",
        "outputId": "cc036e3b-b535-426b-ccbf-55620a7dc59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cupy-cuda92\n",
            "  Downloading cupy_cuda92-9.6.0-cp38-cp38-manylinux1_x86_64.whl (57.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.8/dist-packages (from cupy-cuda92) (0.8.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.17 in /usr/local/lib/python3.8/dist-packages (from cupy-cuda92) (1.21.6)\n",
            "Installing collected packages: cupy-cuda92\n",
            "Successfully installed cupy-cuda92-9.6.0\n",
            "/bin/bash: !pip: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install cupy-cuda92 && \\\n",
        "!pip install pynvrtc && \\\n",
        "!/tmp/clean-layer.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "vubkaYIgvQe-",
        "outputId": "28428785-9a65-48d3-c8b3-6a528a29d252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 276480 candidates, totalling 1382400 fits\n",
            "[CV 1/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.5;, score=-0.014 total time=   1.8s\n",
            "[CV 2/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.5;, score=-0.015 total time=   0.6s\n",
            "[CV 3/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.5;, score=-0.016 total time=   0.6s\n",
            "[CV 4/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.5;, score=-0.017 total time=   0.6s\n",
            "[CV 5/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.5;, score=-0.016 total time=   0.6s\n",
            "[CV 1/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.8;, score=-0.014 total time=   0.7s\n",
            "[CV 2/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.8;, score=-0.015 total time=   0.7s\n",
            "[CV 3/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.8;, score=-0.016 total time=   0.7s\n",
            "[CV 4/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.8;, score=-0.017 total time=   0.6s\n",
            "[CV 5/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=0.8;, score=-0.016 total time=   0.6s\n",
            "[CV 1/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=1.0;, score=-0.014 total time=   0.7s\n",
            "[CV 2/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=1.0;, score=-0.015 total time=   0.7s\n",
            "[CV 3/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=1.0;, score=-0.016 total time=   0.6s\n",
            "[CV 4/5] END colsample_bylevel=0.5, colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.01, reg_lambda=0.01, subsample=1.0;, score=-0.017 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f35af5fad786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         self._Booster = train(params, trainDmatrix,\n\u001b[0m\u001b[1;32m    392\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    213\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0m\u001b[1;32m   1109\u001b[0m                                                     dtrain.handle))\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=2,\n",
        "                          learning_rate=1,\n",
        "                          depth=2)\n",
        "\n",
        "# model = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=-1,tree_method='gpu_hist', gpu_id=0)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 500, 1000],\n",
        "    'subsample': [0.5, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
        "    'colsample_bylevel': [0.5, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 2, 3, 4, 5],\n",
        "    'reg_alpha': [0.01, 0.1, 1.0, 10.0],\n",
        "    'reg_lambda': [0.01, 0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error' , verbose = 5)\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HG89Rv9Vhroo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "ivLdpsVIh2fL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=100,\n",
        "                          task_type=\"GPU\",\n",
        "                          learning_rate=1,\n",
        "                          depth=2, \n",
        "                          eval_metric='r2_score'\n",
        "                          )\n",
        "model.fit(X_train , y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "xoeD8DDp7AR0",
        "outputId": "19031ce0-8556-48cf-967f-76e0c366577d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-20d8f7a9e9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2_score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5728\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5730\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5731\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5732\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2340\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0m_check_param_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_params_type_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0m_check_train_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_fraction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: tools/enum_parser/enum_serialization_runtime/enum_runtime.cpp:70: Key 'r2_score' not found in enum ELossFunction. Valid options are: 'Logloss', 'CrossEntropy', 'CtrFactor', 'RMSE', 'LogCosh', 'Lq', 'MAE', 'Quantile', 'MultiQuantile', 'Expectile', 'LogLinQuantile', 'MAPE', 'Poisson', 'MSLE', 'MedianAbsoluteError', 'SMAPE', 'Huber', 'Tweedie', 'Cox', 'RMSEWithUncertainty', 'MultiClass', 'MultiClassOneVsAll', 'PairLogit', 'PairLogitPairwise', 'YetiRank', 'YetiRankPairwise', 'QueryRMSE', 'QuerySoftMax', 'QueryCrossEntropy', 'StochasticFilter', 'LambdaMart', 'StochasticRank', 'PythonUserDefinedPerObject', 'PythonUserDefinedMultiTarget', 'UserPerObjMetric', 'UserQuerywiseMetric', 'R2', 'NumErrors', 'FairLoss', 'AUC', 'Accuracy', 'BalancedAccuracy', 'BalancedErrorRate', 'BrierScore', 'Precision', 'Recall', 'F1', 'TotalF1', 'F', 'MCC', 'ZeroOneLoss', 'HammingLoss', 'HingeLoss', 'Kappa', 'WKappa', 'LogLikelihoodOfPrediction', 'NormalizedGini', 'PRAUC', 'PairAccuracy', 'AverageGain', 'QueryAverage', 'QueryAUC', 'PFound', 'PrecisionAt', 'RecallAt', 'MAP', 'NDCG', 'DCG', 'FilteredDCG', 'MRR', 'ERR', 'SurvivalAft', 'MultiRMSE', 'MultiRMSEWithMissingValues', 'MultiLogloss', 'MultiCrossEntropy', 'Combination'. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=100,\n",
        "                          task_type=\"GPU\",\n",
        "                          learning_rate=1,\n",
        "                          depth=2, \n",
        "                          eval_metric='r2_score'\n",
        "                          )\n",
        "model.fit(X_train , y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "outputId": "19031ce0-8556-48cf-967f-76e0c366577d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "GJ-JeH0y8iID"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-20d8f7a9e9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2_score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5728\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5730\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5731\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5732\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2340\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0m_check_param_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_params_type_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0m_check_train_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_fraction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: tools/enum_parser/enum_serialization_runtime/enum_runtime.cpp:70: Key 'r2_score' not found in enum ELossFunction. Valid options are: 'Logloss', 'CrossEntropy', 'CtrFactor', 'RMSE', 'LogCosh', 'Lq', 'MAE', 'Quantile', 'MultiQuantile', 'Expectile', 'LogLinQuantile', 'MAPE', 'Poisson', 'MSLE', 'MedianAbsoluteError', 'SMAPE', 'Huber', 'Tweedie', 'Cox', 'RMSEWithUncertainty', 'MultiClass', 'MultiClassOneVsAll', 'PairLogit', 'PairLogitPairwise', 'YetiRank', 'YetiRankPairwise', 'QueryRMSE', 'QuerySoftMax', 'QueryCrossEntropy', 'StochasticFilter', 'LambdaMart', 'StochasticRank', 'PythonUserDefinedPerObject', 'PythonUserDefinedMultiTarget', 'UserPerObjMetric', 'UserQuerywiseMetric', 'R2', 'NumErrors', 'FairLoss', 'AUC', 'Accuracy', 'BalancedAccuracy', 'BalancedErrorRate', 'BrierScore', 'Precision', 'Recall', 'F1', 'TotalF1', 'F', 'MCC', 'ZeroOneLoss', 'HammingLoss', 'HingeLoss', 'Kappa', 'WKappa', 'LogLikelihoodOfPrediction', 'NormalizedGini', 'PRAUC', 'PairAccuracy', 'AverageGain', 'QueryAverage', 'QueryAUC', 'PFound', 'PrecisionAt', 'RecallAt', 'MAP', 'NDCG', 'DCG', 'FilteredDCG', 'MRR', 'ERR', 'SurvivalAft', 'MultiRMSE', 'MultiRMSEWithMissingValues', 'MultiLogloss', 'MultiCrossEntropy', 'Combination'. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=100,\n",
        "                          task_type=\"GPU\",\n",
        "                          learning_rate=1,\n",
        "                          depth=2, \n",
        "                          eval_metric='r2_score'\n",
        "                          )\n",
        "model.fit(X_train , y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "outputId": "19031ce0-8556-48cf-967f-76e0c366577d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "PSPKSwus8nOF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-20d8f7a9e9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2_score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5728\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5730\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5731\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5732\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2340\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0m_check_param_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_params_type_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0m_check_train_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_fraction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: tools/enum_parser/enum_serialization_runtime/enum_runtime.cpp:70: Key 'r2_score' not found in enum ELossFunction. Valid options are: 'Logloss', 'CrossEntropy', 'CtrFactor', 'RMSE', 'LogCosh', 'Lq', 'MAE', 'Quantile', 'MultiQuantile', 'Expectile', 'LogLinQuantile', 'MAPE', 'Poisson', 'MSLE', 'MedianAbsoluteError', 'SMAPE', 'Huber', 'Tweedie', 'Cox', 'RMSEWithUncertainty', 'MultiClass', 'MultiClassOneVsAll', 'PairLogit', 'PairLogitPairwise', 'YetiRank', 'YetiRankPairwise', 'QueryRMSE', 'QuerySoftMax', 'QueryCrossEntropy', 'StochasticFilter', 'LambdaMart', 'StochasticRank', 'PythonUserDefinedPerObject', 'PythonUserDefinedMultiTarget', 'UserPerObjMetric', 'UserQuerywiseMetric', 'R2', 'NumErrors', 'FairLoss', 'AUC', 'Accuracy', 'BalancedAccuracy', 'BalancedErrorRate', 'BrierScore', 'Precision', 'Recall', 'F1', 'TotalF1', 'F', 'MCC', 'ZeroOneLoss', 'HammingLoss', 'HingeLoss', 'Kappa', 'WKappa', 'LogLikelihoodOfPrediction', 'NormalizedGini', 'PRAUC', 'PairAccuracy', 'AverageGain', 'QueryAverage', 'QueryAUC', 'PFound', 'PrecisionAt', 'RecallAt', 'MAP', 'NDCG', 'DCG', 'FilteredDCG', 'MRR', 'ERR', 'SurvivalAft', 'MultiRMSE', 'MultiRMSEWithMissingValues', 'MultiLogloss', 'MultiCrossEntropy', 'Combination'. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=100000,\n",
        "                          task_type=\"GPU\",\n",
        "                          learning_rate=0.01,\n",
        "                          eval_metric='R2'\n",
        "                          )\n",
        "model.fit(X_train , y_train , eval_set = (X_test , y_test))\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "outputId": "abfb3020-87d7-43e1-d313-20f3d2a8bba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aZNV36CY8oSF"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because R2 is/are not implemented for GPU\n",
            "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "67575:\tlearn: 0.9927226\ttest: 0.8765968\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67576:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67577:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67578:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67579:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67580:\tlearn: 0.9927228\ttest: 0.8765948\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67581:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67582:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67583:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67584:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67585:\tlearn: 0.9927229\ttest: 0.8765938\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67586:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67587:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67588:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67589:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67590:\tlearn: 0.9927232\ttest: 0.8765916\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67591:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67592:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67593:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67594:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67595:\tlearn: 0.9927232\ttest: 0.8765910\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67596:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67597:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67598:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67599:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67600:\tlearn: 0.9927233\ttest: 0.8765906\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67601:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67602:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67603:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67604:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67605:\tlearn: 0.9927233\ttest: 0.8765905\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67606:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67607:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67608:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67609:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67610:\tlearn: 0.9927240\ttest: 0.8765906\tbest: 0.8767146 (43570)\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67611:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67612:\ttotal: 12m 13s\tremaining: 5m 51s\n",
            "67613:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67614:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67615:\tlearn: 0.9927247\ttest: 0.8765845\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67616:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67617:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67618:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67619:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67620:\tlearn: 0.9927253\ttest: 0.8765836\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67621:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67622:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67623:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67624:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67625:\tlearn: 0.9927265\ttest: 0.8765810\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67626:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67627:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67628:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67629:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67630:\tlearn: 0.9927265\ttest: 0.8765809\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67631:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67632:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67633:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67634:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67635:\tlearn: 0.9927266\ttest: 0.8765791\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67636:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67637:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67638:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67639:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67640:\tlearn: 0.9927267\ttest: 0.8765796\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67641:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67642:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67643:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67644:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67645:\tlearn: 0.9927269\ttest: 0.8765790\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67646:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67647:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67648:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67649:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67650:\tlearn: 0.9927269\ttest: 0.8765789\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67651:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67652:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67653:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67654:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67655:\tlearn: 0.9927273\ttest: 0.8765758\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67656:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67657:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67658:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67659:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67660:\tlearn: 0.9927278\ttest: 0.8765753\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67661:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67662:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67663:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67664:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67665:\tlearn: 0.9927279\ttest: 0.8765753\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67666:\ttotal: 12m 14s\tremaining: 5m 51s\n",
            "67667:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67668:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67669:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67670:\tlearn: 0.9927285\ttest: 0.8765757\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67671:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67672:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67673:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67674:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67675:\tlearn: 0.9927286\ttest: 0.8765760\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67676:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67677:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67678:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67679:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67680:\tlearn: 0.9927286\ttest: 0.8765756\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67681:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67682:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67683:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67684:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67685:\tlearn: 0.9927287\ttest: 0.8765757\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67686:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67687:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67688:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67689:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67690:\tlearn: 0.9927287\ttest: 0.8765757\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67691:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67692:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67693:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67694:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67695:\tlearn: 0.9927288\ttest: 0.8765750\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67696:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67697:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67698:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67699:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67700:\tlearn: 0.9927288\ttest: 0.8765743\tbest: 0.8767146 (43570)\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67701:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67702:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67703:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67704:\ttotal: 12m 14s\tremaining: 5m 50s\n",
            "67705:\tlearn: 0.9927294\ttest: 0.8765729\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67706:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67707:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67708:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67709:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67710:\tlearn: 0.9927294\ttest: 0.8765715\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67711:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67712:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67713:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67714:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67715:\tlearn: 0.9927294\ttest: 0.8765716\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67716:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67717:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67718:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67719:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67720:\tlearn: 0.9927294\ttest: 0.8765715\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67721:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67722:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67723:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67724:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67725:\tlearn: 0.9927295\ttest: 0.8765717\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67726:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67727:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67728:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67729:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67730:\tlearn: 0.9927295\ttest: 0.8765723\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67731:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67732:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67733:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67734:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67735:\tlearn: 0.9927295\ttest: 0.8765727\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67736:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67737:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67738:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67739:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67740:\tlearn: 0.9927296\ttest: 0.8765720\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67741:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67742:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67743:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67744:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67745:\tlearn: 0.9927296\ttest: 0.8765721\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67746:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67747:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67748:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67749:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67750:\tlearn: 0.9927297\ttest: 0.8765724\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67751:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67752:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67753:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67754:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67755:\tlearn: 0.9927297\ttest: 0.8765724\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67756:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67757:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67758:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67759:\ttotal: 12m 15s\tremaining: 5m 50s\n",
            "67760:\tlearn: 0.9927297\ttest: 0.8765726\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67761:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67762:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67763:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67764:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67765:\tlearn: 0.9927301\ttest: 0.8765727\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67766:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67767:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67768:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67769:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67770:\tlearn: 0.9927304\ttest: 0.8765731\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67771:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67772:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67773:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67774:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67775:\tlearn: 0.9927309\ttest: 0.8765706\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67776:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67777:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67778:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67779:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67780:\tlearn: 0.9927309\ttest: 0.8765707\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67781:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67782:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67783:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67784:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67785:\tlearn: 0.9927309\ttest: 0.8765706\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67786:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67787:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67788:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67789:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67790:\tlearn: 0.9927310\ttest: 0.8765706\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67791:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67792:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67793:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67794:\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67795:\tlearn: 0.9927319\ttest: 0.8765707\tbest: 0.8767146 (43570)\ttotal: 12m 15s\tremaining: 5m 49s\n",
            "67796:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67797:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67798:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67799:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67800:\tlearn: 0.9927319\ttest: 0.8765712\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67801:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67802:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67803:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67804:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67805:\tlearn: 0.9927321\ttest: 0.8765691\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67806:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67807:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67808:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67809:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67810:\tlearn: 0.9927323\ttest: 0.8765689\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67811:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67812:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67813:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67814:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67815:\tlearn: 0.9927323\ttest: 0.8765687\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67816:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67817:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67818:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67819:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67820:\tlearn: 0.9927324\ttest: 0.8765690\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67821:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67822:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67823:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67824:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67825:\tlearn: 0.9927335\ttest: 0.8765703\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67826:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67827:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67828:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67829:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67830:\tlearn: 0.9927342\ttest: 0.8765717\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67831:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67832:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67833:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67834:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67835:\tlearn: 0.9927344\ttest: 0.8765713\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67836:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67837:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67838:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67839:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67840:\tlearn: 0.9927356\ttest: 0.8765688\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67841:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67842:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67843:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67844:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67845:\tlearn: 0.9927356\ttest: 0.8765683\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67846:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67847:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67848:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67849:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67850:\tlearn: 0.9927357\ttest: 0.8765673\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67851:\ttotal: 12m 16s\tremaining: 5m 49s\n",
            "67852:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67853:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67854:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67855:\tlearn: 0.9927402\ttest: 0.8765659\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67856:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67857:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67858:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67859:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67860:\tlearn: 0.9927406\ttest: 0.8765629\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67861:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67862:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67863:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67864:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67865:\tlearn: 0.9927407\ttest: 0.8765621\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67866:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67867:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67868:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67869:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67870:\tlearn: 0.9927407\ttest: 0.8765618\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67871:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67872:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67873:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67874:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67875:\tlearn: 0.9927407\ttest: 0.8765621\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67876:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67877:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67878:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67879:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67880:\tlearn: 0.9927408\ttest: 0.8765621\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67881:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67882:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67883:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67884:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67885:\tlearn: 0.9927421\ttest: 0.8765707\tbest: 0.8767146 (43570)\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67886:\ttotal: 12m 16s\tremaining: 5m 48s\n",
            "67887:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67888:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67889:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67890:\tlearn: 0.9927422\ttest: 0.8765708\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67891:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67892:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67893:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67894:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67895:\tlearn: 0.9927425\ttest: 0.8765703\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67896:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67897:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67898:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67899:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67900:\tlearn: 0.9927425\ttest: 0.8765704\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67901:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67902:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67903:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67904:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67905:\tlearn: 0.9927437\ttest: 0.8765722\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67906:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67907:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67908:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67909:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67910:\tlearn: 0.9927442\ttest: 0.8765681\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67911:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67912:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67913:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67914:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67915:\tlearn: 0.9927446\ttest: 0.8765700\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67916:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67917:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67918:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67919:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67920:\tlearn: 0.9927447\ttest: 0.8765692\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67921:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67922:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67923:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67924:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67925:\tlearn: 0.9927449\ttest: 0.8765677\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67926:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67927:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67928:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67929:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67930:\tlearn: 0.9927450\ttest: 0.8765676\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67931:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67932:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67933:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67934:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67935:\tlearn: 0.9927452\ttest: 0.8765673\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67936:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67937:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67938:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67939:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67940:\tlearn: 0.9927452\ttest: 0.8765673\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67941:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67942:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67943:\ttotal: 12m 17s\tremaining: 5m 48s\n",
            "67944:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67945:\tlearn: 0.9927457\ttest: 0.8765688\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67946:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67947:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67948:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67949:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67950:\tlearn: 0.9927472\ttest: 0.8765683\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67951:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67952:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67953:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67954:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67955:\tlearn: 0.9927472\ttest: 0.8765684\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67956:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67957:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67958:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67959:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67960:\tlearn: 0.9927478\ttest: 0.8765690\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67961:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67962:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67963:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67964:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67965:\tlearn: 0.9927481\ttest: 0.8765655\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67966:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67967:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67968:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67969:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67970:\tlearn: 0.9927481\ttest: 0.8765649\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67971:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67972:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67973:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67974:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67975:\tlearn: 0.9927482\ttest: 0.8765645\tbest: 0.8767146 (43570)\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67976:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67977:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67978:\ttotal: 12m 17s\tremaining: 5m 47s\n",
            "67979:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67980:\tlearn: 0.9927483\ttest: 0.8765666\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67981:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67982:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67983:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67984:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67985:\tlearn: 0.9927485\ttest: 0.8765664\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67986:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67987:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67988:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67989:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67990:\tlearn: 0.9927486\ttest: 0.8765668\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67991:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67992:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67993:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67994:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67995:\tlearn: 0.9927486\ttest: 0.8765667\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67996:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67997:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67998:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "67999:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68000:\tlearn: 0.9927504\ttest: 0.8765675\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68001:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68002:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68003:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68004:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68005:\tlearn: 0.9927523\ttest: 0.8765632\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68006:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68007:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68008:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68009:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68010:\tlearn: 0.9927529\ttest: 0.8765652\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68011:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68012:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68013:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68014:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68015:\tlearn: 0.9927529\ttest: 0.8765652\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68016:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68017:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68018:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68019:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68020:\tlearn: 0.9927537\ttest: 0.8765703\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68021:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68022:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68023:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68024:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68025:\tlearn: 0.9927540\ttest: 0.8765637\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68026:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68027:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68028:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68029:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68030:\tlearn: 0.9927540\ttest: 0.8765638\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68031:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68032:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68033:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68034:\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68035:\tlearn: 0.9927541\ttest: 0.8765628\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 47s\n",
            "68036:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68037:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68038:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68039:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68040:\tlearn: 0.9927554\ttest: 0.8765560\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68041:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68042:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68043:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68044:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68045:\tlearn: 0.9927554\ttest: 0.8765555\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68046:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68047:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68048:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68049:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68050:\tlearn: 0.9927554\ttest: 0.8765547\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68051:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68052:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68053:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68054:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68055:\tlearn: 0.9927556\ttest: 0.8765542\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68056:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68057:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68058:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68059:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68060:\tlearn: 0.9927560\ttest: 0.8765544\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68061:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68062:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68063:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68064:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68065:\tlearn: 0.9927570\ttest: 0.8765570\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68066:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68067:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68068:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68069:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68070:\tlearn: 0.9927575\ttest: 0.8765585\tbest: 0.8767146 (43570)\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68071:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68072:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68073:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68074:\ttotal: 12m 18s\tremaining: 5m 46s\n",
            "68075:\tlearn: 0.9927578\ttest: 0.8765547\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68076:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68077:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68078:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68079:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68080:\tlearn: 0.9927582\ttest: 0.8765497\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68081:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68082:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68083:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68084:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68085:\tlearn: 0.9927583\ttest: 0.8765496\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68086:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68087:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68088:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68089:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68090:\tlearn: 0.9927584\ttest: 0.8765502\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68091:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68092:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68093:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68094:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68095:\tlearn: 0.9927584\ttest: 0.8765506\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68096:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68097:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68098:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68099:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68100:\tlearn: 0.9927585\ttest: 0.8765508\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68101:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68102:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68103:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68104:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68105:\tlearn: 0.9927585\ttest: 0.8765507\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68106:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68107:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68108:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68109:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68110:\tlearn: 0.9927585\ttest: 0.8765509\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68111:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68112:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68113:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68114:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68115:\tlearn: 0.9927586\ttest: 0.8765506\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68116:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68117:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68118:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68119:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68120:\tlearn: 0.9927587\ttest: 0.8765509\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68121:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68122:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68123:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68124:\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68125:\tlearn: 0.9927588\ttest: 0.8765516\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 46s\n",
            "68126:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68127:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68128:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68129:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68130:\tlearn: 0.9927588\ttest: 0.8765513\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68131:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68132:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68133:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68134:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68135:\tlearn: 0.9927596\ttest: 0.8765494\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68136:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68137:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68138:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68139:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68140:\tlearn: 0.9927602\ttest: 0.8765424\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68141:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68142:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68143:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68144:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68145:\tlearn: 0.9927603\ttest: 0.8765427\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68146:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68147:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68148:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68149:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68150:\tlearn: 0.9927605\ttest: 0.8765379\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68151:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68152:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68153:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68154:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68155:\tlearn: 0.9927606\ttest: 0.8765367\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68156:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68157:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68158:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68159:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68160:\tlearn: 0.9927608\ttest: 0.8765387\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68161:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68162:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68163:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68164:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68165:\tlearn: 0.9927609\ttest: 0.8765384\tbest: 0.8767146 (43570)\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68166:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68167:\ttotal: 12m 19s\tremaining: 5m 45s\n",
            "68168:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68169:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68170:\tlearn: 0.9927615\ttest: 0.8765326\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68171:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68172:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68173:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68174:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68175:\tlearn: 0.9927616\ttest: 0.8765311\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68176:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68177:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68178:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68179:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68180:\tlearn: 0.9927617\ttest: 0.8765296\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68181:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68182:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68183:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68184:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68185:\tlearn: 0.9927618\ttest: 0.8765297\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68186:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68187:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68188:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68189:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68190:\tlearn: 0.9927619\ttest: 0.8765296\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68191:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68192:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68193:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68194:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68195:\tlearn: 0.9927620\ttest: 0.8765311\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68196:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68197:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68198:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68199:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68200:\tlearn: 0.9927624\ttest: 0.8765308\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68201:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68202:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68203:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68204:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68205:\tlearn: 0.9927624\ttest: 0.8765311\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68206:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68207:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68208:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68209:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68210:\tlearn: 0.9927628\ttest: 0.8765339\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68211:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68212:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68213:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68214:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68215:\tlearn: 0.9927629\ttest: 0.8765349\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68216:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68217:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68218:\ttotal: 12m 20s\tremaining: 5m 45s\n",
            "68219:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68220:\tlearn: 0.9927640\ttest: 0.8765305\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68221:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68222:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68223:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68224:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68225:\tlearn: 0.9927642\ttest: 0.8765316\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68226:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68227:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68228:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68229:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68230:\tlearn: 0.9927650\ttest: 0.8765262\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68231:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68232:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68233:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68234:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68235:\tlearn: 0.9927675\ttest: 0.8765224\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68236:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68237:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68238:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68239:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68240:\tlearn: 0.9927675\ttest: 0.8765222\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68241:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68242:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68243:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68244:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68245:\tlearn: 0.9927680\ttest: 0.8765252\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68246:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68247:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68248:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68249:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68250:\tlearn: 0.9927680\ttest: 0.8765252\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68251:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68252:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68253:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68254:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68255:\tlearn: 0.9927681\ttest: 0.8765262\tbest: 0.8767146 (43570)\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68256:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68257:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68258:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68259:\ttotal: 12m 20s\tremaining: 5m 44s\n",
            "68260:\tlearn: 0.9927681\ttest: 0.8765261\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68261:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68262:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68263:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68264:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68265:\tlearn: 0.9927682\ttest: 0.8765261\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68266:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68267:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68268:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68269:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68270:\tlearn: 0.9927693\ttest: 0.8765273\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68271:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68272:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68273:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68274:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68275:\tlearn: 0.9927704\ttest: 0.8765288\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68276:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68277:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68278:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68279:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68280:\tlearn: 0.9927704\ttest: 0.8765290\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68281:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68282:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68283:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68284:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68285:\tlearn: 0.9927712\ttest: 0.8765267\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68286:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68287:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68288:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68289:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68290:\tlearn: 0.9927714\ttest: 0.8765278\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68291:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68292:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68293:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68294:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68295:\tlearn: 0.9927727\ttest: 0.8765261\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68296:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68297:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68298:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68299:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68300:\tlearn: 0.9927736\ttest: 0.8765292\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68301:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68302:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68303:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68304:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68305:\tlearn: 0.9927736\ttest: 0.8765282\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68306:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68307:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68308:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68309:\ttotal: 12m 21s\tremaining: 5m 44s\n",
            "68310:\tlearn: 0.9927737\ttest: 0.8765292\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68311:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68312:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68313:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68314:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68315:\tlearn: 0.9927749\ttest: 0.8765298\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68316:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68317:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68318:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68319:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68320:\tlearn: 0.9927750\ttest: 0.8765299\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68321:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68322:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68323:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68324:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68325:\tlearn: 0.9927758\ttest: 0.8765211\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68326:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68327:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68328:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68329:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68330:\tlearn: 0.9927761\ttest: 0.8765180\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68331:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68332:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68333:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68334:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68335:\tlearn: 0.9927768\ttest: 0.8765199\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68336:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68337:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68338:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68339:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68340:\tlearn: 0.9927769\ttest: 0.8765189\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68341:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68342:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68343:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68344:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68345:\tlearn: 0.9927770\ttest: 0.8765202\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68346:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68347:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68348:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68349:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68350:\tlearn: 0.9927773\ttest: 0.8765202\tbest: 0.8767146 (43570)\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68351:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68352:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68353:\ttotal: 12m 21s\tremaining: 5m 43s\n",
            "68354:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68355:\tlearn: 0.9927774\ttest: 0.8765208\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68356:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68357:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68358:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68359:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68360:\tlearn: 0.9927787\ttest: 0.8765253\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68361:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68362:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68363:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68364:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68365:\tlearn: 0.9927787\ttest: 0.8765252\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68366:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68367:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68368:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68369:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68370:\tlearn: 0.9927804\ttest: 0.8765224\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68371:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68372:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68373:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68374:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68375:\tlearn: 0.9927805\ttest: 0.8765251\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68376:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68377:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68378:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68379:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68380:\tlearn: 0.9927853\ttest: 0.8765248\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68381:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68382:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68383:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68384:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68385:\tlearn: 0.9927861\ttest: 0.8765273\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68386:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68387:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68388:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68389:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68390:\tlearn: 0.9927877\ttest: 0.8765259\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68391:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68392:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68393:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68394:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68395:\tlearn: 0.9927877\ttest: 0.8765263\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68396:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68397:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68398:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68399:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68400:\tlearn: 0.9927899\ttest: 0.8765339\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68401:\ttotal: 12m 22s\tremaining: 5m 43s\n",
            "68402:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68403:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68404:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68405:\tlearn: 0.9927901\ttest: 0.8765367\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68406:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68407:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68408:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68409:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68410:\tlearn: 0.9927901\ttest: 0.8765365\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68411:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68412:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68413:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68414:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68415:\tlearn: 0.9927905\ttest: 0.8765374\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68416:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68417:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68418:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68419:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68420:\tlearn: 0.9927916\ttest: 0.8765347\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68421:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68422:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68423:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68424:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68425:\tlearn: 0.9927917\ttest: 0.8765348\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68426:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68427:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68428:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68429:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68430:\tlearn: 0.9927920\ttest: 0.8765316\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68431:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68432:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68433:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68434:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68435:\tlearn: 0.9927931\ttest: 0.8765331\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68436:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68437:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68438:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68439:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68440:\tlearn: 0.9927942\ttest: 0.8765336\tbest: 0.8767146 (43570)\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68441:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68442:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68443:\ttotal: 12m 22s\tremaining: 5m 42s\n",
            "68444:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68445:\tlearn: 0.9927942\ttest: 0.8765329\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68446:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68447:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68448:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68449:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68450:\tlearn: 0.9927943\ttest: 0.8765327\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68451:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68452:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68453:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68454:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68455:\tlearn: 0.9927944\ttest: 0.8765310\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68456:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68457:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68458:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68459:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68460:\tlearn: 0.9927946\ttest: 0.8765312\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68461:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68462:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68463:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68464:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68465:\tlearn: 0.9927947\ttest: 0.8765325\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68466:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68467:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68468:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68469:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68470:\tlearn: 0.9927949\ttest: 0.8765309\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68471:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68472:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68473:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68474:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68475:\tlearn: 0.9927961\ttest: 0.8765269\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68476:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68477:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68478:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68479:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68480:\tlearn: 0.9927975\ttest: 0.8765226\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68481:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68482:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68483:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68484:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68485:\tlearn: 0.9927982\ttest: 0.8765200\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68486:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68487:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68488:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68489:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68490:\tlearn: 0.9927983\ttest: 0.8765198\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68491:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68492:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68493:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68494:\ttotal: 12m 23s\tremaining: 5m 42s\n",
            "68495:\tlearn: 0.9927986\ttest: 0.8765189\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68496:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68497:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68498:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68499:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68500:\tlearn: 0.9927987\ttest: 0.8765187\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68501:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68502:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68503:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68504:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68505:\tlearn: 0.9927989\ttest: 0.8765154\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68506:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68507:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68508:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68509:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68510:\tlearn: 0.9927998\ttest: 0.8765134\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68511:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68512:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68513:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68514:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68515:\tlearn: 0.9927999\ttest: 0.8765133\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68516:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68517:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68518:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68519:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68520:\tlearn: 0.9928015\ttest: 0.8765087\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68521:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68522:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68523:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68524:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68525:\tlearn: 0.9928020\ttest: 0.8765090\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68526:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68527:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68528:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68529:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68530:\tlearn: 0.9928021\ttest: 0.8765087\tbest: 0.8767146 (43570)\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68531:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68532:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68533:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68534:\ttotal: 12m 23s\tremaining: 5m 41s\n",
            "68535:\tlearn: 0.9928024\ttest: 0.8765056\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68536:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68537:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68538:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68539:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68540:\tlearn: 0.9928025\ttest: 0.8765065\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68541:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68542:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68543:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68544:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68545:\tlearn: 0.9928026\ttest: 0.8765079\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68546:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68547:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68548:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68549:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68550:\tlearn: 0.9928027\ttest: 0.8765080\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68551:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68552:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68553:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68554:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68555:\tlearn: 0.9928029\ttest: 0.8765088\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68556:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68557:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68558:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68559:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68560:\tlearn: 0.9928039\ttest: 0.8765073\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68561:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68562:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68563:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68564:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68565:\tlearn: 0.9928039\ttest: 0.8765074\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68566:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68567:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68568:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68569:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68570:\tlearn: 0.9928040\ttest: 0.8765067\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68571:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68572:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68573:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68574:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68575:\tlearn: 0.9928043\ttest: 0.8765085\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68576:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68577:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68578:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68579:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68580:\tlearn: 0.9928050\ttest: 0.8765125\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68581:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68582:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68583:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68584:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68585:\tlearn: 0.9928050\ttest: 0.8765138\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68586:\ttotal: 12m 24s\tremaining: 5m 41s\n",
            "68587:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68588:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68589:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68590:\tlearn: 0.9928051\ttest: 0.8765136\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68591:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68592:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68593:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68594:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68595:\tlearn: 0.9928054\ttest: 0.8765145\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68596:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68597:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68598:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68599:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68600:\tlearn: 0.9928056\ttest: 0.8765134\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68601:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68602:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68603:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68604:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68605:\tlearn: 0.9928057\ttest: 0.8765126\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68606:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68607:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68608:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68609:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68610:\tlearn: 0.9928058\ttest: 0.8765132\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68611:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68612:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68613:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68614:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68615:\tlearn: 0.9928058\ttest: 0.8765132\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68616:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68617:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68618:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68619:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68620:\tlearn: 0.9928059\ttest: 0.8765132\tbest: 0.8767146 (43570)\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68621:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68622:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68623:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68624:\ttotal: 12m 24s\tremaining: 5m 40s\n",
            "68625:\tlearn: 0.9928061\ttest: 0.8765148\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68626:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68627:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68628:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68629:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68630:\tlearn: 0.9928062\ttest: 0.8765139\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68631:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68632:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68633:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68634:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68635:\tlearn: 0.9928067\ttest: 0.8765146\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68636:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68637:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68638:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68639:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68640:\tlearn: 0.9928068\ttest: 0.8765140\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68641:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68642:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68643:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68644:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68645:\tlearn: 0.9928068\ttest: 0.8765140\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68646:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68647:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68648:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68649:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68650:\tlearn: 0.9928077\ttest: 0.8765129\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68651:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68652:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68653:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68654:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68655:\tlearn: 0.9928077\ttest: 0.8765127\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68656:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68657:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68658:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68659:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68660:\tlearn: 0.9928077\ttest: 0.8765125\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68661:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68662:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68663:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68664:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68665:\tlearn: 0.9928089\ttest: 0.8765129\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68666:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68667:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68668:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68669:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68670:\tlearn: 0.9928089\ttest: 0.8765134\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68671:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68672:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68673:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68674:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68675:\tlearn: 0.9928093\ttest: 0.8765097\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68676:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68677:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68678:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68679:\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68680:\tlearn: 0.9928093\ttest: 0.8765095\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 40s\n",
            "68681:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68682:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68683:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68684:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68685:\tlearn: 0.9928094\ttest: 0.8765094\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68686:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68687:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68688:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68689:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68690:\tlearn: 0.9928095\ttest: 0.8765113\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68691:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68692:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68693:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68694:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68695:\tlearn: 0.9928107\ttest: 0.8765210\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68696:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68697:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68698:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68699:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68700:\tlearn: 0.9928121\ttest: 0.8765196\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68701:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68702:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68703:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68704:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68705:\tlearn: 0.9928121\ttest: 0.8765196\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68706:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68707:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68708:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68709:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68710:\tlearn: 0.9928122\ttest: 0.8765188\tbest: 0.8767146 (43570)\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68711:\ttotal: 12m 25s\tremaining: 5m 39s\n",
            "68712:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68713:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68714:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68715:\tlearn: 0.9928129\ttest: 0.8765205\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68716:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68717:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68718:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68719:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68720:\tlearn: 0.9928130\ttest: 0.8765205\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68721:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68722:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68723:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68724:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68725:\tlearn: 0.9928130\ttest: 0.8765206\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68726:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68727:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68728:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68729:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68730:\tlearn: 0.9928160\ttest: 0.8765215\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68731:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68732:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68733:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68734:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68735:\tlearn: 0.9928161\ttest: 0.8765208\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68736:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68737:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68738:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68739:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68740:\tlearn: 0.9928163\ttest: 0.8765243\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68741:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68742:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68743:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68744:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68745:\tlearn: 0.9928165\ttest: 0.8765237\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68746:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68747:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68748:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68749:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68750:\tlearn: 0.9928168\ttest: 0.8765239\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68751:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68752:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68753:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68754:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68755:\tlearn: 0.9928171\ttest: 0.8765225\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68756:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68757:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68758:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68759:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68760:\tlearn: 0.9928171\ttest: 0.8765219\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68761:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68762:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68763:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68764:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68765:\tlearn: 0.9928171\ttest: 0.8765216\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68766:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68767:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68768:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68769:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68770:\tlearn: 0.9928172\ttest: 0.8765215\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68771:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68772:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68773:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68774:\ttotal: 12m 26s\tremaining: 5m 39s\n",
            "68775:\tlearn: 0.9928172\ttest: 0.8765213\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68776:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68777:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68778:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68779:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68780:\tlearn: 0.9928180\ttest: 0.8765160\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68781:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68782:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68783:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68784:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68785:\tlearn: 0.9928181\ttest: 0.8765160\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68786:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68787:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68788:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68789:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68790:\tlearn: 0.9928186\ttest: 0.8765184\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68791:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68792:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68793:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68794:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68795:\tlearn: 0.9928188\ttest: 0.8765170\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68796:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68797:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68798:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68799:\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68800:\tlearn: 0.9928198\ttest: 0.8765202\tbest: 0.8767146 (43570)\ttotal: 12m 26s\tremaining: 5m 38s\n",
            "68801:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68802:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68803:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68804:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68805:\tlearn: 0.9928198\ttest: 0.8765199\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68806:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68807:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68808:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68809:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68810:\tlearn: 0.9928203\ttest: 0.8765173\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68811:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68812:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68813:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68814:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68815:\tlearn: 0.9928203\ttest: 0.8765170\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68816:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68817:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68818:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68819:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68820:\tlearn: 0.9928204\ttest: 0.8765163\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68821:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68822:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68823:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68824:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68825:\tlearn: 0.9928205\ttest: 0.8765148\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68826:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68827:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68828:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68829:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68830:\tlearn: 0.9928206\ttest: 0.8765147\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68831:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68832:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68833:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68834:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68835:\tlearn: 0.9928208\ttest: 0.8765137\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68836:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68837:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68838:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68839:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68840:\tlearn: 0.9928208\ttest: 0.8765137\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68841:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68842:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68843:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68844:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68845:\tlearn: 0.9928210\ttest: 0.8765084\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68846:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68847:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68848:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68849:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68850:\tlearn: 0.9928212\ttest: 0.8765070\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68851:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68852:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68853:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68854:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68855:\tlearn: 0.9928213\ttest: 0.8765041\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68856:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68857:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68858:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68859:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68860:\tlearn: 0.9928214\ttest: 0.8765023\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68861:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68862:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68863:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68864:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68865:\tlearn: 0.9928214\ttest: 0.8765024\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68866:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68867:\ttotal: 12m 27s\tremaining: 5m 38s\n",
            "68868:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68869:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68870:\tlearn: 0.9928215\ttest: 0.8765026\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68871:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68872:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68873:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68874:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68875:\tlearn: 0.9928216\ttest: 0.8765019\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68876:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68877:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68878:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68879:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68880:\tlearn: 0.9928217\ttest: 0.8765001\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68881:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68882:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68883:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68884:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68885:\tlearn: 0.9928217\ttest: 0.8764998\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68886:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68887:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68888:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68889:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68890:\tlearn: 0.9928217\ttest: 0.8764999\tbest: 0.8767146 (43570)\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68891:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68892:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68893:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68894:\ttotal: 12m 27s\tremaining: 5m 37s\n",
            "68895:\tlearn: 0.9928228\ttest: 0.8765002\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68896:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68897:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68898:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68899:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68900:\tlearn: 0.9928228\ttest: 0.8765003\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68901:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68902:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68903:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68904:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68905:\tlearn: 0.9928229\ttest: 0.8764970\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68906:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68907:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68908:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68909:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68910:\tlearn: 0.9928230\ttest: 0.8764960\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68911:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68912:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68913:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68914:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68915:\tlearn: 0.9928231\ttest: 0.8764955\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68916:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68917:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68918:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68919:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68920:\tlearn: 0.9928231\ttest: 0.8764958\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68921:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68922:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68923:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68924:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68925:\tlearn: 0.9928232\ttest: 0.8764956\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68926:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68927:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68928:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68929:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68930:\tlearn: 0.9928233\ttest: 0.8764954\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68931:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68932:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68933:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68934:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68935:\tlearn: 0.9928233\ttest: 0.8764951\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68936:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68937:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68938:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68939:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68940:\tlearn: 0.9928234\ttest: 0.8764939\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68941:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68942:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68943:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68944:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68945:\tlearn: 0.9928244\ttest: 0.8765040\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68946:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68947:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68948:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68949:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68950:\tlearn: 0.9928245\ttest: 0.8765041\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68951:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68952:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68953:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68954:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68955:\tlearn: 0.9928246\ttest: 0.8765051\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68956:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68957:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68958:\ttotal: 12m 28s\tremaining: 5m 37s\n",
            "68959:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68960:\tlearn: 0.9928249\ttest: 0.8765045\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68961:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68962:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68963:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68964:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68965:\tlearn: 0.9928250\ttest: 0.8765036\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68966:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68967:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68968:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68969:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68970:\tlearn: 0.9928250\ttest: 0.8765027\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68971:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68972:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68973:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68974:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68975:\tlearn: 0.9928256\ttest: 0.8764988\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68976:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68977:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68978:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68979:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68980:\tlearn: 0.9928257\ttest: 0.8764990\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68981:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68982:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68983:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68984:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68985:\tlearn: 0.9928257\ttest: 0.8764982\tbest: 0.8767146 (43570)\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68986:\ttotal: 12m 28s\tremaining: 5m 36s\n",
            "68987:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68988:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68989:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68990:\tlearn: 0.9928258\ttest: 0.8764972\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68991:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68992:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68993:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68994:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68995:\tlearn: 0.9928259\ttest: 0.8764970\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68996:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68997:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68998:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "68999:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69000:\tlearn: 0.9928268\ttest: 0.8764936\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69001:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69002:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69003:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69004:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69005:\tlearn: 0.9928268\ttest: 0.8764933\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69006:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69007:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69008:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69009:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69010:\tlearn: 0.9928269\ttest: 0.8764934\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69011:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69012:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69013:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69014:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69015:\tlearn: 0.9928274\ttest: 0.8764930\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69016:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69017:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69018:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69019:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69020:\tlearn: 0.9928278\ttest: 0.8764918\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69021:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69022:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69023:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69024:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69025:\tlearn: 0.9928283\ttest: 0.8764927\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69026:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69027:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69028:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69029:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69030:\tlearn: 0.9928284\ttest: 0.8764928\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69031:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69032:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69033:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69034:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69035:\tlearn: 0.9928284\ttest: 0.8764933\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69036:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69037:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69038:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69039:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69040:\tlearn: 0.9928285\ttest: 0.8764925\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69041:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69042:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69043:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69044:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69045:\tlearn: 0.9928285\ttest: 0.8764918\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69046:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69047:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69048:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69049:\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69050:\tlearn: 0.9928286\ttest: 0.8764908\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 36s\n",
            "69051:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69052:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69053:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69054:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69055:\tlearn: 0.9928287\ttest: 0.8764888\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69056:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69057:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69058:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69059:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69060:\tlearn: 0.9928287\ttest: 0.8764878\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69061:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69062:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69063:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69064:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69065:\tlearn: 0.9928287\ttest: 0.8764876\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69066:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69067:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69068:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69069:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69070:\tlearn: 0.9928287\ttest: 0.8764879\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69071:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69072:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69073:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69074:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69075:\tlearn: 0.9928289\ttest: 0.8764891\tbest: 0.8767146 (43570)\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69076:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69077:\ttotal: 12m 29s\tremaining: 5m 35s\n",
            "69078:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69079:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69080:\tlearn: 0.9928302\ttest: 0.8764915\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69081:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69082:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69083:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69084:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69085:\tlearn: 0.9928303\ttest: 0.8764913\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69086:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69087:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69088:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69089:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69090:\tlearn: 0.9928304\ttest: 0.8764910\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69091:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69092:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69093:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69094:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69095:\tlearn: 0.9928305\ttest: 0.8764904\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69096:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69097:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69098:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69099:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69100:\tlearn: 0.9928315\ttest: 0.8764893\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69101:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69102:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69103:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69104:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69105:\tlearn: 0.9928317\ttest: 0.8764887\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69106:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69107:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69108:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69109:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69110:\tlearn: 0.9928318\ttest: 0.8764885\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69111:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69112:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69113:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69114:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69115:\tlearn: 0.9928318\ttest: 0.8764880\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69116:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69117:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69118:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69119:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69120:\tlearn: 0.9928323\ttest: 0.8764893\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69121:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69122:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69123:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69124:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69125:\tlearn: 0.9928327\ttest: 0.8764873\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69126:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69127:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69128:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69129:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69130:\tlearn: 0.9928328\ttest: 0.8764871\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69131:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69132:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69133:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69134:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69135:\tlearn: 0.9928331\ttest: 0.8764885\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69136:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69137:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69138:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69139:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69140:\tlearn: 0.9928331\ttest: 0.8764879\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69141:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69142:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69143:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69144:\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69145:\tlearn: 0.9928331\ttest: 0.8764880\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 35s\n",
            "69146:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69147:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69148:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69149:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69150:\tlearn: 0.9928332\ttest: 0.8764861\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69151:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69152:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69153:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69154:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69155:\tlearn: 0.9928333\ttest: 0.8764865\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69156:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69157:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69158:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69159:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69160:\tlearn: 0.9928333\ttest: 0.8764863\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69161:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69162:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69163:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69164:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69165:\tlearn: 0.9928341\ttest: 0.8764847\tbest: 0.8767146 (43570)\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69166:\ttotal: 12m 30s\tremaining: 5m 34s\n",
            "69167:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69168:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69169:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69170:\tlearn: 0.9928341\ttest: 0.8764825\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69171:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69172:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69173:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69174:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69175:\tlearn: 0.9928344\ttest: 0.8764820\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69176:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69177:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69178:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69179:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69180:\tlearn: 0.9928345\ttest: 0.8764806\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69181:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69182:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69183:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69184:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69185:\tlearn: 0.9928346\ttest: 0.8764780\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69186:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69187:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69188:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69189:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69190:\tlearn: 0.9928346\ttest: 0.8764779\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69191:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69192:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69193:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69194:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69195:\tlearn: 0.9928346\ttest: 0.8764788\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69196:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69197:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69198:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69199:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69200:\tlearn: 0.9928348\ttest: 0.8764796\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69201:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69202:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69203:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69204:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69205:\tlearn: 0.9928348\ttest: 0.8764795\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69206:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69207:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69208:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69209:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69210:\tlearn: 0.9928351\ttest: 0.8764791\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69211:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69212:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69213:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69214:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69215:\tlearn: 0.9928351\ttest: 0.8764792\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69216:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69217:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69218:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69219:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69220:\tlearn: 0.9928351\ttest: 0.8764793\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69221:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69222:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69223:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69224:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69225:\tlearn: 0.9928351\ttest: 0.8764792\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69226:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69227:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69228:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69229:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69230:\tlearn: 0.9928357\ttest: 0.8764744\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69231:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69232:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69233:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69234:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69235:\tlearn: 0.9928357\ttest: 0.8764745\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69236:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69237:\ttotal: 12m 31s\tremaining: 5m 34s\n",
            "69238:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69239:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69240:\tlearn: 0.9928357\ttest: 0.8764744\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69241:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69242:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69243:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69244:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69245:\tlearn: 0.9928362\ttest: 0.8764731\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69246:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69247:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69248:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69249:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69250:\tlearn: 0.9928362\ttest: 0.8764729\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69251:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69252:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69253:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69254:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69255:\tlearn: 0.9928362\ttest: 0.8764719\tbest: 0.8767146 (43570)\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69256:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69257:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69258:\ttotal: 12m 31s\tremaining: 5m 33s\n",
            "69259:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69260:\tlearn: 0.9928365\ttest: 0.8764719\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69261:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69262:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69263:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69264:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69265:\tlearn: 0.9928365\ttest: 0.8764718\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69266:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69267:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69268:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69269:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69270:\tlearn: 0.9928367\ttest: 0.8764652\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69271:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69272:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69273:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69274:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69275:\tlearn: 0.9928367\ttest: 0.8764632\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69276:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69277:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69278:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69279:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69280:\tlearn: 0.9928368\ttest: 0.8764647\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69281:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69282:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69283:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69284:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69285:\tlearn: 0.9928376\ttest: 0.8764654\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69286:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69287:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69288:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69289:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69290:\tlearn: 0.9928380\ttest: 0.8764694\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69291:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69292:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69293:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69294:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69295:\tlearn: 0.9928380\ttest: 0.8764693\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69296:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69297:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69298:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69299:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69300:\tlearn: 0.9928381\ttest: 0.8764695\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69301:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69302:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69303:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69304:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69305:\tlearn: 0.9928381\ttest: 0.8764693\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69306:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69307:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69308:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69309:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69310:\tlearn: 0.9928381\ttest: 0.8764683\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69311:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69312:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69313:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69314:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69315:\tlearn: 0.9928384\ttest: 0.8764693\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69316:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69317:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69318:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69319:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69320:\tlearn: 0.9928399\ttest: 0.8764699\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69321:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69322:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69323:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69324:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69325:\tlearn: 0.9928399\ttest: 0.8764696\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69326:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69327:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69328:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69329:\ttotal: 12m 32s\tremaining: 5m 33s\n",
            "69330:\tlearn: 0.9928407\ttest: 0.8764625\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69331:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69332:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69333:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69334:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69335:\tlearn: 0.9928407\ttest: 0.8764625\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69336:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69337:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69338:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69339:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69340:\tlearn: 0.9928407\ttest: 0.8764622\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69341:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69342:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69343:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69344:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69345:\tlearn: 0.9928408\ttest: 0.8764611\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69346:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69347:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69348:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69349:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69350:\tlearn: 0.9928408\ttest: 0.8764613\tbest: 0.8767146 (43570)\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69351:\ttotal: 12m 32s\tremaining: 5m 32s\n",
            "69352:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69353:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69354:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69355:\tlearn: 0.9928415\ttest: 0.8764627\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69356:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69357:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69358:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69359:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69360:\tlearn: 0.9928419\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69361:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69362:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69363:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69364:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69365:\tlearn: 0.9928420\ttest: 0.8764615\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69366:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69367:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69368:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69369:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69370:\tlearn: 0.9928431\ttest: 0.8764636\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69371:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69372:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69373:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69374:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69375:\tlearn: 0.9928431\ttest: 0.8764636\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69376:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69377:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69378:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69379:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69380:\tlearn: 0.9928456\ttest: 0.8764656\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69381:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69382:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69383:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69384:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69385:\tlearn: 0.9928456\ttest: 0.8764661\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69386:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69387:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69388:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69389:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69390:\tlearn: 0.9928458\ttest: 0.8764687\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69391:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69392:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69393:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69394:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69395:\tlearn: 0.9928459\ttest: 0.8764686\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69396:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69397:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69398:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69399:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69400:\tlearn: 0.9928459\ttest: 0.8764676\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69401:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69402:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69403:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69404:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69405:\tlearn: 0.9928464\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69406:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69407:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69408:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69409:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69410:\tlearn: 0.9928472\ttest: 0.8764611\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69411:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69412:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69413:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69414:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69415:\tlearn: 0.9928474\ttest: 0.8764596\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69416:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69417:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69418:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69419:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69420:\tlearn: 0.9928475\ttest: 0.8764617\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69421:\ttotal: 12m 33s\tremaining: 5m 32s\n",
            "69422:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69423:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69424:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69425:\tlearn: 0.9928476\ttest: 0.8764617\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69426:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69427:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69428:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69429:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69430:\tlearn: 0.9928477\ttest: 0.8764620\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69431:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69432:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69433:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69434:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69435:\tlearn: 0.9928484\ttest: 0.8764638\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69436:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69437:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69438:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69439:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69440:\tlearn: 0.9928484\ttest: 0.8764631\tbest: 0.8767146 (43570)\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69441:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69442:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69443:\ttotal: 12m 33s\tremaining: 5m 31s\n",
            "69444:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69445:\tlearn: 0.9928485\ttest: 0.8764628\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69446:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69447:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69448:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69449:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69450:\tlearn: 0.9928485\ttest: 0.8764625\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69451:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69452:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69453:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69454:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69455:\tlearn: 0.9928494\ttest: 0.8764619\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69456:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69457:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69458:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69459:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69460:\tlearn: 0.9928495\ttest: 0.8764621\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69461:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69462:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69463:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69464:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69465:\tlearn: 0.9928504\ttest: 0.8764651\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69466:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69467:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69468:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69469:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69470:\tlearn: 0.9928504\ttest: 0.8764652\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69471:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69472:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69473:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69474:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69475:\tlearn: 0.9928508\ttest: 0.8764652\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69476:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69477:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69478:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69479:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69480:\tlearn: 0.9928509\ttest: 0.8764624\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69481:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69482:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69483:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69484:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69485:\tlearn: 0.9928510\ttest: 0.8764615\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69486:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69487:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69488:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69489:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69490:\tlearn: 0.9928512\ttest: 0.8764603\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69491:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69492:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69493:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69494:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69495:\tlearn: 0.9928513\ttest: 0.8764597\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69496:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69497:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69498:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69499:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69500:\tlearn: 0.9928552\ttest: 0.8764749\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69501:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69502:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69503:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69504:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69505:\tlearn: 0.9928553\ttest: 0.8764737\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69506:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69507:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69508:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69509:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69510:\tlearn: 0.9928554\ttest: 0.8764733\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69511:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69512:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69513:\ttotal: 12m 34s\tremaining: 5m 31s\n",
            "69514:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69515:\tlearn: 0.9928556\ttest: 0.8764729\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69516:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69517:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69518:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69519:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69520:\tlearn: 0.9928565\ttest: 0.8764718\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69521:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69522:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69523:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69524:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69525:\tlearn: 0.9928565\ttest: 0.8764716\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69526:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69527:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69528:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69529:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69530:\tlearn: 0.9928570\ttest: 0.8764730\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69531:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69532:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69533:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69534:\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69535:\tlearn: 0.9928581\ttest: 0.8764742\tbest: 0.8767146 (43570)\ttotal: 12m 34s\tremaining: 5m 30s\n",
            "69536:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69537:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69538:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69539:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69540:\tlearn: 0.9928590\ttest: 0.8764751\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69541:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69542:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69543:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69544:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69545:\tlearn: 0.9928592\ttest: 0.8764741\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69546:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69547:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69548:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69549:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69550:\tlearn: 0.9928596\ttest: 0.8764767\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69551:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69552:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69553:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69554:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69555:\tlearn: 0.9928597\ttest: 0.8764774\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69556:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69557:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69558:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69559:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69560:\tlearn: 0.9928599\ttest: 0.8764774\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69561:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69562:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69563:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69564:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69565:\tlearn: 0.9928601\ttest: 0.8764763\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69566:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69567:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69568:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69569:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69570:\tlearn: 0.9928604\ttest: 0.8764760\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69571:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69572:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69573:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69574:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69575:\tlearn: 0.9928607\ttest: 0.8764728\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69576:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69577:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69578:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69579:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69580:\tlearn: 0.9928607\ttest: 0.8764730\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69581:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69582:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69583:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69584:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69585:\tlearn: 0.9928608\ttest: 0.8764735\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69586:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69587:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69588:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69589:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69590:\tlearn: 0.9928609\ttest: 0.8764766\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69591:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69592:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69593:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69594:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69595:\tlearn: 0.9928619\ttest: 0.8764791\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69596:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69597:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69598:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69599:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69600:\tlearn: 0.9928620\ttest: 0.8764784\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69601:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69602:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69603:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69604:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69605:\tlearn: 0.9928625\ttest: 0.8764759\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69606:\ttotal: 12m 35s\tremaining: 5m 30s\n",
            "69607:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69608:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69609:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69610:\tlearn: 0.9928625\ttest: 0.8764757\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69611:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69612:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69613:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69614:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69615:\tlearn: 0.9928630\ttest: 0.8764732\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69616:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69617:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69618:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69619:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69620:\tlearn: 0.9928631\ttest: 0.8764721\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69621:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69622:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69623:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69624:\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69625:\tlearn: 0.9928631\ttest: 0.8764715\tbest: 0.8767146 (43570)\ttotal: 12m 35s\tremaining: 5m 29s\n",
            "69626:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69627:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69628:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69629:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69630:\tlearn: 0.9928632\ttest: 0.8764715\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69631:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69632:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69633:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69634:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69635:\tlearn: 0.9928635\ttest: 0.8764691\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69636:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69637:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69638:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69639:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69640:\tlearn: 0.9928639\ttest: 0.8764693\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69641:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69642:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69643:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69644:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69645:\tlearn: 0.9928640\ttest: 0.8764681\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69646:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69647:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69648:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69649:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69650:\tlearn: 0.9928640\ttest: 0.8764682\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69651:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69652:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69653:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69654:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69655:\tlearn: 0.9928640\ttest: 0.8764681\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69656:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69657:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69658:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69659:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69660:\tlearn: 0.9928640\ttest: 0.8764684\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69661:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69662:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69663:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69664:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69665:\tlearn: 0.9928640\ttest: 0.8764692\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69666:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69667:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69668:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69669:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69670:\tlearn: 0.9928643\ttest: 0.8764625\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69671:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69672:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69673:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69674:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69675:\tlearn: 0.9928648\ttest: 0.8764615\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69676:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69677:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69678:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69679:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69680:\tlearn: 0.9928648\ttest: 0.8764614\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69681:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69682:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69683:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69684:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69685:\tlearn: 0.9928648\ttest: 0.8764622\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69686:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69687:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69688:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69689:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69690:\tlearn: 0.9928649\ttest: 0.8764632\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69691:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69692:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69693:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69694:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69695:\tlearn: 0.9928678\ttest: 0.8764663\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69696:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69697:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69698:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69699:\ttotal: 12m 36s\tremaining: 5m 29s\n",
            "69700:\tlearn: 0.9928681\ttest: 0.8764670\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69701:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69702:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69703:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69704:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69705:\tlearn: 0.9928682\ttest: 0.8764665\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69706:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69707:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69708:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69709:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69710:\tlearn: 0.9928682\ttest: 0.8764663\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69711:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69712:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69713:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69714:\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69715:\tlearn: 0.9928682\ttest: 0.8764662\tbest: 0.8767146 (43570)\ttotal: 12m 36s\tremaining: 5m 28s\n",
            "69716:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69717:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69718:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69719:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69720:\tlearn: 0.9928683\ttest: 0.8764657\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69721:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69722:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69723:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69724:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69725:\tlearn: 0.9928683\ttest: 0.8764638\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69726:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69727:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69728:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69729:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69730:\tlearn: 0.9928684\ttest: 0.8764636\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69731:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69732:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69733:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69734:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69735:\tlearn: 0.9928691\ttest: 0.8764670\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69736:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69737:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69738:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69739:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69740:\tlearn: 0.9928695\ttest: 0.8764641\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69741:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69742:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69743:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69744:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69745:\tlearn: 0.9928698\ttest: 0.8764636\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69746:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69747:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69748:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69749:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69750:\tlearn: 0.9928698\ttest: 0.8764636\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69751:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69752:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69753:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69754:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69755:\tlearn: 0.9928740\ttest: 0.8764657\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69756:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69757:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69758:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69759:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69760:\tlearn: 0.9928742\ttest: 0.8764668\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69761:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69762:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69763:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69764:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69765:\tlearn: 0.9928744\ttest: 0.8764655\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69766:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69767:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69768:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69769:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69770:\tlearn: 0.9928748\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69771:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69772:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69773:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69774:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69775:\tlearn: 0.9928749\ttest: 0.8764599\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69776:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69777:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69778:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69779:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69780:\tlearn: 0.9928752\ttest: 0.8764559\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69781:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69782:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69783:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69784:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69785:\tlearn: 0.9928763\ttest: 0.8764537\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69786:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69787:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69788:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69789:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69790:\tlearn: 0.9928772\ttest: 0.8764546\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69791:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69792:\ttotal: 12m 37s\tremaining: 5m 28s\n",
            "69793:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69794:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69795:\tlearn: 0.9928794\ttest: 0.8764572\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69796:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69797:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69798:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69799:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69800:\tlearn: 0.9928794\ttest: 0.8764570\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69801:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69802:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69803:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69804:\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69805:\tlearn: 0.9928795\ttest: 0.8764585\tbest: 0.8767146 (43570)\ttotal: 12m 37s\tremaining: 5m 27s\n",
            "69806:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69807:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69808:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69809:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69810:\tlearn: 0.9928795\ttest: 0.8764579\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69811:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69812:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69813:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69814:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69815:\tlearn: 0.9928797\ttest: 0.8764609\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69816:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69817:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69818:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69819:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69820:\tlearn: 0.9928797\ttest: 0.8764608\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69821:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69822:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69823:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69824:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69825:\tlearn: 0.9928797\ttest: 0.8764599\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69826:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69827:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69828:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69829:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69830:\tlearn: 0.9928798\ttest: 0.8764603\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69831:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69832:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69833:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69834:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69835:\tlearn: 0.9928799\ttest: 0.8764607\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69836:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69837:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69838:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69839:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69840:\tlearn: 0.9928803\ttest: 0.8764601\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69841:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69842:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69843:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69844:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69845:\tlearn: 0.9928803\ttest: 0.8764602\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69846:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69847:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69848:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69849:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69850:\tlearn: 0.9928804\ttest: 0.8764581\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69851:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69852:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69853:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69854:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69855:\tlearn: 0.9928805\ttest: 0.8764580\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69856:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69857:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69858:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69859:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69860:\tlearn: 0.9928805\ttest: 0.8764582\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69861:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69862:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69863:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69864:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69865:\tlearn: 0.9928817\ttest: 0.8764649\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69866:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69867:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69868:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69869:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69870:\tlearn: 0.9928819\ttest: 0.8764648\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69871:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69872:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69873:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69874:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69875:\tlearn: 0.9928819\ttest: 0.8764646\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69876:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69877:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69878:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69879:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69880:\tlearn: 0.9928819\ttest: 0.8764647\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69881:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69882:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69883:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69884:\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69885:\tlearn: 0.9928820\ttest: 0.8764638\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 27s\n",
            "69886:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69887:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69888:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69889:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69890:\tlearn: 0.9928820\ttest: 0.8764631\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69891:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69892:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69893:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69894:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69895:\tlearn: 0.9928828\ttest: 0.8764623\tbest: 0.8767146 (43570)\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69896:\ttotal: 12m 38s\tremaining: 5m 26s\n",
            "69897:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69898:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69899:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69900:\tlearn: 0.9928829\ttest: 0.8764631\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69901:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69902:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69903:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69904:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69905:\tlearn: 0.9928831\ttest: 0.8764627\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69906:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69907:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69908:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69909:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69910:\tlearn: 0.9928832\ttest: 0.8764632\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69911:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69912:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69913:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69914:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69915:\tlearn: 0.9928832\ttest: 0.8764625\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69916:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69917:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69918:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69919:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69920:\tlearn: 0.9928832\ttest: 0.8764623\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69921:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69922:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69923:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69924:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69925:\tlearn: 0.9928833\ttest: 0.8764607\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69926:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69927:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69928:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69929:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69930:\tlearn: 0.9928849\ttest: 0.8764587\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69931:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69932:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69933:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69934:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69935:\tlearn: 0.9928851\ttest: 0.8764598\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69936:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69937:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69938:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69939:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69940:\tlearn: 0.9928853\ttest: 0.8764576\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69941:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69942:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69943:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69944:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69945:\tlearn: 0.9928869\ttest: 0.8764554\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69946:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69947:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69948:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69949:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69950:\tlearn: 0.9928869\ttest: 0.8764543\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69951:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69952:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69953:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69954:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69955:\tlearn: 0.9928871\ttest: 0.8764555\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69956:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69957:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69958:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69959:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69960:\tlearn: 0.9928883\ttest: 0.8764557\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69961:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69962:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69963:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69964:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69965:\tlearn: 0.9928893\ttest: 0.8764544\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69966:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69967:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69968:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69969:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69970:\tlearn: 0.9928895\ttest: 0.8764555\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69971:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69972:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69973:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69974:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69975:\tlearn: 0.9928900\ttest: 0.8764555\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69976:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69977:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69978:\ttotal: 12m 39s\tremaining: 5m 26s\n",
            "69979:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69980:\tlearn: 0.9928902\ttest: 0.8764539\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69981:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69982:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69983:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69984:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69985:\tlearn: 0.9928903\ttest: 0.8764535\tbest: 0.8767146 (43570)\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69986:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69987:\ttotal: 12m 39s\tremaining: 5m 25s\n",
            "69988:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69989:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69990:\tlearn: 0.9928903\ttest: 0.8764539\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69991:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69992:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69993:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69994:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69995:\tlearn: 0.9928913\ttest: 0.8764504\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69996:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69997:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69998:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "69999:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70000:\tlearn: 0.9928914\ttest: 0.8764501\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70001:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70002:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70003:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70004:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70005:\tlearn: 0.9928914\ttest: 0.8764490\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70006:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70007:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70008:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70009:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70010:\tlearn: 0.9928915\ttest: 0.8764489\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70011:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70012:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70013:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70014:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70015:\tlearn: 0.9928917\ttest: 0.8764481\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70016:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70017:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70018:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70019:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70020:\tlearn: 0.9928923\ttest: 0.8764497\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70021:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70022:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70023:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70024:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70025:\tlearn: 0.9928952\ttest: 0.8764541\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70026:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70027:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70028:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70029:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70030:\tlearn: 0.9928952\ttest: 0.8764541\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70031:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70032:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70033:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70034:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70035:\tlearn: 0.9928952\ttest: 0.8764545\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70036:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70037:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70038:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70039:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70040:\tlearn: 0.9928953\ttest: 0.8764554\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70041:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70042:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70043:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70044:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70045:\tlearn: 0.9928954\ttest: 0.8764570\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70046:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70047:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70048:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70049:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70050:\tlearn: 0.9928972\ttest: 0.8764531\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70051:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70052:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70053:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70054:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70055:\tlearn: 0.9928991\ttest: 0.8764619\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70056:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70057:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70058:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70059:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70060:\tlearn: 0.9928992\ttest: 0.8764620\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70061:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70062:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70063:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70064:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70065:\tlearn: 0.9928992\ttest: 0.8764626\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70066:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70067:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70068:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70069:\ttotal: 12m 40s\tremaining: 5m 25s\n",
            "70070:\tlearn: 0.9928993\ttest: 0.8764633\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70071:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70072:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70073:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70074:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70075:\tlearn: 0.9928994\ttest: 0.8764640\tbest: 0.8767146 (43570)\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70076:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70077:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70078:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70079:\ttotal: 12m 40s\tremaining: 5m 24s\n",
            "70080:\tlearn: 0.9928996\ttest: 0.8764630\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70081:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70082:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70083:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70084:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70085:\tlearn: 0.9928996\ttest: 0.8764630\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70086:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70087:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70088:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70089:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70090:\tlearn: 0.9929005\ttest: 0.8764603\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70091:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70092:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70093:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70094:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70095:\tlearn: 0.9929006\ttest: 0.8764615\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70096:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70097:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70098:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70099:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70100:\tlearn: 0.9929009\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70101:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70102:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70103:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70104:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70105:\tlearn: 0.9929010\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70106:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70107:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70108:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70109:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70110:\tlearn: 0.9929012\ttest: 0.8764598\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70111:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70112:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70113:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70114:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70115:\tlearn: 0.9929012\ttest: 0.8764599\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70116:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70117:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70118:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70119:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70120:\tlearn: 0.9929013\ttest: 0.8764597\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70121:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70122:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70123:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70124:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70125:\tlearn: 0.9929013\ttest: 0.8764576\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70126:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70127:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70128:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70129:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70130:\tlearn: 0.9929016\ttest: 0.8764609\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70131:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70132:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70133:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70134:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70135:\tlearn: 0.9929017\ttest: 0.8764617\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70136:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70137:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70138:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70139:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70140:\tlearn: 0.9929017\ttest: 0.8764618\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70141:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70142:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70143:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70144:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70145:\tlearn: 0.9929017\ttest: 0.8764620\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70146:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70147:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70148:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70149:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70150:\tlearn: 0.9929019\ttest: 0.8764653\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70151:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70152:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70153:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70154:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70155:\tlearn: 0.9929020\ttest: 0.8764649\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70156:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70157:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70158:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70159:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70160:\tlearn: 0.9929020\ttest: 0.8764634\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70161:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70162:\ttotal: 12m 41s\tremaining: 5m 24s\n",
            "70163:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70164:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70165:\tlearn: 0.9929029\ttest: 0.8764611\tbest: 0.8767146 (43570)\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70166:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70167:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70168:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70169:\ttotal: 12m 41s\tremaining: 5m 23s\n",
            "70170:\tlearn: 0.9929030\ttest: 0.8764604\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70171:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70172:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70173:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70174:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70175:\tlearn: 0.9929030\ttest: 0.8764603\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70176:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70177:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70178:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70179:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70180:\tlearn: 0.9929031\ttest: 0.8764604\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70181:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70182:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70183:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70184:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70185:\tlearn: 0.9929040\ttest: 0.8764616\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70186:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70187:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70188:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70189:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70190:\tlearn: 0.9929053\ttest: 0.8764604\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70191:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70192:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70193:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70194:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70195:\tlearn: 0.9929055\ttest: 0.8764598\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70196:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70197:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70198:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70199:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70200:\tlearn: 0.9929070\ttest: 0.8764632\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70201:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70202:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70203:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70204:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70205:\tlearn: 0.9929073\ttest: 0.8764640\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70206:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70207:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70208:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70209:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70210:\tlearn: 0.9929098\ttest: 0.8764677\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70211:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70212:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70213:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70214:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70215:\tlearn: 0.9929098\ttest: 0.8764676\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70216:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70217:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70218:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70219:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70220:\tlearn: 0.9929098\ttest: 0.8764685\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70221:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70222:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70223:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70224:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70225:\tlearn: 0.9929099\ttest: 0.8764685\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70226:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70227:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70228:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70229:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70230:\tlearn: 0.9929110\ttest: 0.8764680\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70231:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70232:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70233:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70234:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70235:\tlearn: 0.9929110\ttest: 0.8764682\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70236:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70237:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70238:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70239:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70240:\tlearn: 0.9929111\ttest: 0.8764681\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70241:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70242:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70243:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70244:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70245:\tlearn: 0.9929117\ttest: 0.8764686\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70246:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70247:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70248:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70249:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70250:\tlearn: 0.9929118\ttest: 0.8764691\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70251:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70252:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70253:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70254:\ttotal: 12m 42s\tremaining: 5m 23s\n",
            "70255:\tlearn: 0.9929143\ttest: 0.8764638\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70256:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70257:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70258:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70259:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70260:\tlearn: 0.9929143\ttest: 0.8764639\tbest: 0.8767146 (43570)\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70261:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70262:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70263:\ttotal: 12m 42s\tremaining: 5m 22s\n",
            "70264:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70265:\tlearn: 0.9929144\ttest: 0.8764623\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70266:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70267:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70268:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70269:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70270:\tlearn: 0.9929145\ttest: 0.8764610\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70271:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70272:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70273:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70274:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70275:\tlearn: 0.9929155\ttest: 0.8764605\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70276:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70277:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70278:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70279:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70280:\tlearn: 0.9929157\ttest: 0.8764585\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70281:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70282:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70283:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70284:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70285:\tlearn: 0.9929164\ttest: 0.8764615\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70286:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70287:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70288:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70289:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70290:\tlearn: 0.9929165\ttest: 0.8764608\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70291:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70292:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70293:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70294:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70295:\tlearn: 0.9929165\ttest: 0.8764587\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70296:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70297:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70298:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70299:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70300:\tlearn: 0.9929167\ttest: 0.8764598\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70301:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70302:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70303:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70304:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70305:\tlearn: 0.9929167\ttest: 0.8764594\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70306:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70307:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70308:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70309:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70310:\tlearn: 0.9929168\ttest: 0.8764604\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70311:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70312:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70313:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70314:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70315:\tlearn: 0.9929183\ttest: 0.8764595\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70316:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70317:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70318:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70319:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70320:\tlearn: 0.9929183\ttest: 0.8764588\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70321:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70322:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70323:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70324:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70325:\tlearn: 0.9929184\ttest: 0.8764597\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70326:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70327:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70328:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70329:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70330:\tlearn: 0.9929185\ttest: 0.8764609\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70331:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70332:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70333:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70334:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70335:\tlearn: 0.9929185\ttest: 0.8764609\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70336:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70337:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70338:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70339:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70340:\tlearn: 0.9929194\ttest: 0.8764634\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70341:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70342:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70343:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70344:\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70345:\tlearn: 0.9929198\ttest: 0.8764605\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 22s\n",
            "70346:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70347:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70348:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70349:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70350:\tlearn: 0.9929199\ttest: 0.8764613\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70351:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70352:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70353:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70354:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70355:\tlearn: 0.9929199\ttest: 0.8764622\tbest: 0.8767146 (43570)\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70356:\ttotal: 12m 43s\tremaining: 5m 21s\n",
            "70357:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70358:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70359:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70360:\tlearn: 0.9929200\ttest: 0.8764640\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70361:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70362:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70363:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70364:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70365:\tlearn: 0.9929201\ttest: 0.8764623\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70366:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70367:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70368:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70369:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70370:\tlearn: 0.9929202\ttest: 0.8764617\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70371:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70372:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70373:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70374:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70375:\tlearn: 0.9929202\ttest: 0.8764613\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70376:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70377:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70378:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70379:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70380:\tlearn: 0.9929203\ttest: 0.8764610\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70381:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70382:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70383:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70384:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70385:\tlearn: 0.9929203\ttest: 0.8764612\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70386:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70387:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70388:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70389:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70390:\tlearn: 0.9929205\ttest: 0.8764599\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70391:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70392:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70393:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70394:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70395:\tlearn: 0.9929205\ttest: 0.8764599\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70396:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70397:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70398:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70399:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70400:\tlearn: 0.9929206\ttest: 0.8764596\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70401:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70402:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70403:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70404:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70405:\tlearn: 0.9929206\ttest: 0.8764593\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70406:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70407:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70408:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70409:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70410:\tlearn: 0.9929206\ttest: 0.8764584\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70411:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70412:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70413:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70414:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70415:\tlearn: 0.9929206\ttest: 0.8764584\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70416:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70417:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70418:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70419:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70420:\tlearn: 0.9929213\ttest: 0.8764576\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70421:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70422:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70423:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70424:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70425:\tlearn: 0.9929215\ttest: 0.8764562\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70426:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70427:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70428:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70429:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70430:\tlearn: 0.9929215\ttest: 0.8764560\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70431:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70432:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70433:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70434:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70435:\tlearn: 0.9929216\ttest: 0.8764549\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70436:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70437:\ttotal: 12m 44s\tremaining: 5m 21s\n",
            "70438:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70439:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70440:\tlearn: 0.9929216\ttest: 0.8764549\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70441:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70442:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70443:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70444:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70445:\tlearn: 0.9929216\ttest: 0.8764550\tbest: 0.8767146 (43570)\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70446:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70447:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70448:\ttotal: 12m 44s\tremaining: 5m 20s\n",
            "70449:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70450:\tlearn: 0.9929228\ttest: 0.8764574\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70451:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70452:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70453:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70454:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70455:\tlearn: 0.9929229\ttest: 0.8764560\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70456:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70457:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70458:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70459:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70460:\tlearn: 0.9929248\ttest: 0.8764508\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70461:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70462:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70463:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70464:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70465:\tlearn: 0.9929249\ttest: 0.8764506\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70466:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70467:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70468:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70469:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70470:\tlearn: 0.9929250\ttest: 0.8764480\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70471:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70472:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70473:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70474:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70475:\tlearn: 0.9929264\ttest: 0.8764481\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70476:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70477:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70478:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70479:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70480:\tlearn: 0.9929264\ttest: 0.8764478\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70481:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70482:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70483:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70484:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70485:\tlearn: 0.9929272\ttest: 0.8764517\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70486:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70487:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70488:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70489:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70490:\tlearn: 0.9929273\ttest: 0.8764520\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70491:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70492:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70493:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70494:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70495:\tlearn: 0.9929273\ttest: 0.8764527\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70496:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70497:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70498:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70499:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70500:\tlearn: 0.9929274\ttest: 0.8764530\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70501:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70502:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70503:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70504:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70505:\tlearn: 0.9929275\ttest: 0.8764528\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70506:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70507:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70508:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70509:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70510:\tlearn: 0.9929279\ttest: 0.8764515\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70511:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70512:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70513:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70514:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70515:\tlearn: 0.9929280\ttest: 0.8764498\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70516:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70517:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70518:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70519:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70520:\tlearn: 0.9929281\ttest: 0.8764469\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70521:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70522:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70523:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70524:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70525:\tlearn: 0.9929285\ttest: 0.8764408\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70526:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70527:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70528:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70529:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70530:\tlearn: 0.9929286\ttest: 0.8764409\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70531:\ttotal: 12m 45s\tremaining: 5m 20s\n",
            "70532:\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70533:\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70534:\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70535:\tlearn: 0.9929286\ttest: 0.8764404\tbest: 0.8767146 (43570)\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70536:\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70537:\ttotal: 12m 45s\tremaining: 5m 19s\n",
            "70538:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70539:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70540:\tlearn: 0.9929286\ttest: 0.8764406\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70541:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70542:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70543:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70544:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70545:\tlearn: 0.9929287\ttest: 0.8764407\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70546:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70547:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70548:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70549:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70550:\tlearn: 0.9929287\ttest: 0.8764406\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70551:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70552:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70553:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70554:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70555:\tlearn: 0.9929290\ttest: 0.8764401\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70556:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70557:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70558:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70559:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70560:\tlearn: 0.9929295\ttest: 0.8764395\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70561:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70562:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70563:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70564:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70565:\tlearn: 0.9929296\ttest: 0.8764398\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70566:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70567:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70568:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70569:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70570:\tlearn: 0.9929298\ttest: 0.8764386\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70571:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70572:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70573:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70574:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70575:\tlearn: 0.9929302\ttest: 0.8764355\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70576:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70577:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70578:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70579:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70580:\tlearn: 0.9929303\ttest: 0.8764338\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70581:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70582:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70583:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70584:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70585:\tlearn: 0.9929304\ttest: 0.8764343\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70586:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70587:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70588:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70589:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70590:\tlearn: 0.9929308\ttest: 0.8764327\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70591:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70592:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70593:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70594:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70595:\tlearn: 0.9929308\ttest: 0.8764327\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70596:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70597:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70598:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70599:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70600:\tlearn: 0.9929313\ttest: 0.8764284\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70601:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70602:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70603:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70604:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70605:\tlearn: 0.9929328\ttest: 0.8764383\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70606:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70607:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70608:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70609:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70610:\tlearn: 0.9929328\ttest: 0.8764380\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70611:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70612:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70613:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70614:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70615:\tlearn: 0.9929328\ttest: 0.8764377\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70616:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70617:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70618:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70619:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70620:\tlearn: 0.9929328\ttest: 0.8764374\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70621:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70622:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70623:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70624:\ttotal: 12m 46s\tremaining: 5m 19s\n",
            "70625:\tlearn: 0.9929328\ttest: 0.8764372\tbest: 0.8767146 (43570)\ttotal: 12m 46s\tremaining: 5m 18s\n",
            "70626:\ttotal: 12m 46s\tremaining: 5m 18s\n",
            "70627:\ttotal: 12m 46s\tremaining: 5m 18s\n",
            "70628:\ttotal: 12m 46s\tremaining: 5m 18s\n",
            "70629:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70630:\tlearn: 0.9929330\ttest: 0.8764382\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70631:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70632:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70633:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70634:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70635:\tlearn: 0.9929331\ttest: 0.8764370\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70636:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70637:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70638:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70639:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70640:\tlearn: 0.9929350\ttest: 0.8764336\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70641:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70642:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70643:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70644:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70645:\tlearn: 0.9929350\ttest: 0.8764334\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70646:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70647:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70648:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70649:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70650:\tlearn: 0.9929350\ttest: 0.8764333\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70651:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70652:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70653:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70654:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70655:\tlearn: 0.9929350\ttest: 0.8764337\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70656:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70657:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70658:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70659:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70660:\tlearn: 0.9929351\ttest: 0.8764331\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70661:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70662:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70663:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70664:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70665:\tlearn: 0.9929353\ttest: 0.8764329\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70666:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70667:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70668:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70669:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70670:\tlearn: 0.9929354\ttest: 0.8764309\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70671:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70672:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70673:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70674:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70675:\tlearn: 0.9929355\ttest: 0.8764303\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70676:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70677:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70678:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70679:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70680:\tlearn: 0.9929356\ttest: 0.8764299\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70681:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70682:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70683:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70684:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70685:\tlearn: 0.9929356\ttest: 0.8764299\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70686:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70687:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70688:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70689:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70690:\tlearn: 0.9929357\ttest: 0.8764286\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70691:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70692:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70693:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70694:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70695:\tlearn: 0.9929383\ttest: 0.8764364\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70696:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70697:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70698:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70699:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70700:\tlearn: 0.9929395\ttest: 0.8764353\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70701:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70702:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70703:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70704:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70705:\tlearn: 0.9929396\ttest: 0.8764347\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70706:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70707:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70708:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70709:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70710:\tlearn: 0.9929397\ttest: 0.8764352\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70711:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70712:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70713:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70714:\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70715:\tlearn: 0.9929398\ttest: 0.8764351\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 18s\n",
            "70716:\ttotal: 12m 47s\tremaining: 5m 17s\n",
            "70717:\ttotal: 12m 47s\tremaining: 5m 17s\n",
            "70718:\ttotal: 12m 47s\tremaining: 5m 17s\n",
            "70719:\ttotal: 12m 47s\tremaining: 5m 17s\n",
            "70720:\tlearn: 0.9929399\ttest: 0.8764364\tbest: 0.8767146 (43570)\ttotal: 12m 47s\tremaining: 5m 17s\n",
            "70721:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70722:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70723:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70724:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70725:\tlearn: 0.9929400\ttest: 0.8764372\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70726:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70727:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70728:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70729:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70730:\tlearn: 0.9929400\ttest: 0.8764367\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70731:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70732:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70733:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70734:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70735:\tlearn: 0.9929401\ttest: 0.8764385\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70736:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70737:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70738:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70739:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70740:\tlearn: 0.9929405\ttest: 0.8764377\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70741:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70742:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70743:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70744:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70745:\tlearn: 0.9929405\ttest: 0.8764373\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70746:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70747:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70748:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70749:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70750:\tlearn: 0.9929405\ttest: 0.8764364\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70751:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70752:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70753:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70754:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70755:\tlearn: 0.9929411\ttest: 0.8764361\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70756:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70757:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70758:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70759:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70760:\tlearn: 0.9929412\ttest: 0.8764360\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70761:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70762:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70763:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70764:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70765:\tlearn: 0.9929412\ttest: 0.8764348\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70766:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70767:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70768:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70769:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70770:\tlearn: 0.9929413\ttest: 0.8764341\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70771:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70772:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70773:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70774:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70775:\tlearn: 0.9929413\ttest: 0.8764346\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70776:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70777:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70778:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70779:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70780:\tlearn: 0.9929414\ttest: 0.8764357\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70781:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70782:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70783:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70784:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70785:\tlearn: 0.9929415\ttest: 0.8764363\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70786:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70787:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70788:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70789:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70790:\tlearn: 0.9929415\ttest: 0.8764365\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70791:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70792:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70793:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70794:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70795:\tlearn: 0.9929416\ttest: 0.8764385\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70796:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70797:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70798:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70799:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70800:\tlearn: 0.9929416\ttest: 0.8764383\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70801:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70802:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70803:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70804:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70805:\tlearn: 0.9929420\ttest: 0.8764395\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70806:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70807:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70808:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70809:\ttotal: 12m 48s\tremaining: 5m 17s\n",
            "70810:\tlearn: 0.9929424\ttest: 0.8764350\tbest: 0.8767146 (43570)\ttotal: 12m 48s\tremaining: 5m 16s\n",
            "70811:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70812:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70813:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70814:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70815:\tlearn: 0.9929426\ttest: 0.8764324\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70816:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70817:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70818:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70819:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70820:\tlearn: 0.9929429\ttest: 0.8764306\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70821:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70822:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70823:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70824:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70825:\tlearn: 0.9929430\ttest: 0.8764296\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70826:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70827:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70828:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70829:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70830:\tlearn: 0.9929430\ttest: 0.8764294\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70831:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70832:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70833:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70834:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70835:\tlearn: 0.9929433\ttest: 0.8764295\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70836:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70837:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70838:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70839:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70840:\tlearn: 0.9929433\ttest: 0.8764292\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70841:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70842:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70843:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70844:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70845:\tlearn: 0.9929433\ttest: 0.8764292\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70846:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70847:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70848:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70849:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70850:\tlearn: 0.9929445\ttest: 0.8764243\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70851:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70852:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70853:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70854:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70855:\tlearn: 0.9929445\ttest: 0.8764246\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70856:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70857:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70858:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70859:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70860:\tlearn: 0.9929445\ttest: 0.8764246\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70861:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70862:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70863:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70864:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70865:\tlearn: 0.9929447\ttest: 0.8764254\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70866:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70867:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70868:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70869:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70870:\tlearn: 0.9929447\ttest: 0.8764253\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70871:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70872:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70873:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70874:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70875:\tlearn: 0.9929461\ttest: 0.8764200\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70876:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70877:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70878:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70879:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70880:\tlearn: 0.9929461\ttest: 0.8764195\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70881:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70882:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70883:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70884:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70885:\tlearn: 0.9929461\ttest: 0.8764193\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70886:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70887:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70888:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70889:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70890:\tlearn: 0.9929461\ttest: 0.8764188\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70891:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70892:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70893:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70894:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70895:\tlearn: 0.9929473\ttest: 0.8764231\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70896:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70897:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70898:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70899:\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70900:\tlearn: 0.9929474\ttest: 0.8764237\tbest: 0.8767146 (43570)\ttotal: 12m 49s\tremaining: 5m 16s\n",
            "70901:\ttotal: 12m 49s\tremaining: 5m 15s\n",
            "70902:\ttotal: 12m 49s\tremaining: 5m 15s\n",
            "70903:\ttotal: 12m 49s\tremaining: 5m 15s\n",
            "70904:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70905:\tlearn: 0.9929479\ttest: 0.8764252\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70906:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70907:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70908:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70909:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70910:\tlearn: 0.9929479\ttest: 0.8764255\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70911:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70912:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70913:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70914:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70915:\tlearn: 0.9929479\ttest: 0.8764256\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70916:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70917:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70918:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70919:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70920:\tlearn: 0.9929486\ttest: 0.8764289\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70921:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70922:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70923:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70924:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70925:\tlearn: 0.9929486\ttest: 0.8764295\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70926:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70927:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70928:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70929:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70930:\tlearn: 0.9929487\ttest: 0.8764297\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70931:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70932:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70933:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70934:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70935:\tlearn: 0.9929487\ttest: 0.8764306\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70936:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70937:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70938:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70939:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70940:\tlearn: 0.9929489\ttest: 0.8764302\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70941:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70942:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70943:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70944:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70945:\tlearn: 0.9929491\ttest: 0.8764301\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70946:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70947:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70948:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70949:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70950:\tlearn: 0.9929495\ttest: 0.8764270\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70951:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70952:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70953:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70954:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70955:\tlearn: 0.9929495\ttest: 0.8764284\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70956:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70957:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70958:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70959:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70960:\tlearn: 0.9929495\ttest: 0.8764283\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70961:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70962:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70963:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70964:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70965:\tlearn: 0.9929496\ttest: 0.8764272\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70966:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70967:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70968:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70969:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70970:\tlearn: 0.9929496\ttest: 0.8764270\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70971:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70972:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70973:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70974:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70975:\tlearn: 0.9929497\ttest: 0.8764275\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70976:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70977:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70978:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70979:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70980:\tlearn: 0.9929497\ttest: 0.8764274\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70981:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70982:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70983:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70984:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70985:\tlearn: 0.9929497\ttest: 0.8764276\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70986:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70987:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70988:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70989:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70990:\tlearn: 0.9929500\ttest: 0.8764313\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70991:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70992:\ttotal: 12m 50s\tremaining: 5m 15s\n",
            "70993:\ttotal: 12m 50s\tremaining: 5m 14s\n",
            "70994:\ttotal: 12m 50s\tremaining: 5m 14s\n",
            "70995:\tlearn: 0.9929504\ttest: 0.8764303\tbest: 0.8767146 (43570)\ttotal: 12m 50s\tremaining: 5m 14s\n",
            "70996:\ttotal: 12m 50s\tremaining: 5m 14s\n",
            "70997:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "70998:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "70999:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71000:\tlearn: 0.9929504\ttest: 0.8764319\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71001:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71002:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71003:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71004:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71005:\tlearn: 0.9929505\ttest: 0.8764313\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71006:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71007:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71008:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71009:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71010:\tlearn: 0.9929505\ttest: 0.8764311\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71011:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71012:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71013:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71014:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71015:\tlearn: 0.9929506\ttest: 0.8764305\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71016:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71017:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71018:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71019:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71020:\tlearn: 0.9929506\ttest: 0.8764310\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71021:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71022:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71023:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71024:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71025:\tlearn: 0.9929507\ttest: 0.8764307\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71026:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71027:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71028:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71029:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71030:\tlearn: 0.9929507\ttest: 0.8764311\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71031:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71032:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71033:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71034:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71035:\tlearn: 0.9929507\ttest: 0.8764311\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71036:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71037:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71038:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71039:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71040:\tlearn: 0.9929507\ttest: 0.8764312\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71041:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71042:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71043:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71044:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71045:\tlearn: 0.9929507\ttest: 0.8764310\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71046:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71047:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71048:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71049:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71050:\tlearn: 0.9929507\ttest: 0.8764304\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71051:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71052:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71053:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71054:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71055:\tlearn: 0.9929513\ttest: 0.8764302\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71056:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71057:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71058:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71059:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71060:\tlearn: 0.9929514\ttest: 0.8764319\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71061:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71062:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71063:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71064:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71065:\tlearn: 0.9929515\ttest: 0.8764332\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71066:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71067:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71068:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71069:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71070:\tlearn: 0.9929515\ttest: 0.8764325\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71071:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71072:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71073:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71074:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71075:\tlearn: 0.9929527\ttest: 0.8764299\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71076:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71077:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71078:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71079:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71080:\tlearn: 0.9929528\ttest: 0.8764307\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71081:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71082:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71083:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71084:\ttotal: 12m 51s\tremaining: 5m 14s\n",
            "71085:\tlearn: 0.9929529\ttest: 0.8764298\tbest: 0.8767146 (43570)\ttotal: 12m 51s\tremaining: 5m 13s\n",
            "71086:\ttotal: 12m 51s\tremaining: 5m 13s\n",
            "71087:\ttotal: 12m 51s\tremaining: 5m 13s\n",
            "71088:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71089:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71090:\tlearn: 0.9929532\ttest: 0.8764305\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71091:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71092:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71093:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71094:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71095:\tlearn: 0.9929539\ttest: 0.8764235\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71096:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71097:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71098:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71099:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71100:\tlearn: 0.9929540\ttest: 0.8764222\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71101:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71102:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71103:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71104:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71105:\tlearn: 0.9929540\ttest: 0.8764219\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71106:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71107:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71108:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71109:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71110:\tlearn: 0.9929540\ttest: 0.8764220\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71111:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71112:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71113:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71114:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71115:\tlearn: 0.9929541\ttest: 0.8764216\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71116:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71117:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71118:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71119:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71120:\tlearn: 0.9929542\ttest: 0.8764213\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71121:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71122:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71123:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71124:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71125:\tlearn: 0.9929542\ttest: 0.8764207\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71126:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71127:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71128:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71129:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71130:\tlearn: 0.9929560\ttest: 0.8764081\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71131:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71132:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71133:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71134:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71135:\tlearn: 0.9929561\ttest: 0.8764076\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71136:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71137:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71138:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71139:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71140:\tlearn: 0.9929561\ttest: 0.8764070\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71141:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71142:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71143:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71144:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71145:\tlearn: 0.9929561\ttest: 0.8764070\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71146:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71147:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71148:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71149:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71150:\tlearn: 0.9929561\ttest: 0.8764070\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71151:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71152:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71153:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71154:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71155:\tlearn: 0.9929561\ttest: 0.8764068\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71156:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71157:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71158:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71159:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71160:\tlearn: 0.9929562\ttest: 0.8764057\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71161:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71162:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71163:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71164:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71165:\tlearn: 0.9929565\ttest: 0.8764062\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71166:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71167:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71168:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71169:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71170:\tlearn: 0.9929566\ttest: 0.8764055\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71171:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71172:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71173:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71174:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71175:\tlearn: 0.9929567\ttest: 0.8764062\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71176:\ttotal: 12m 52s\tremaining: 5m 13s\n",
            "71177:\ttotal: 12m 52s\tremaining: 5m 12s\n",
            "71178:\ttotal: 12m 52s\tremaining: 5m 12s\n",
            "71179:\ttotal: 12m 52s\tremaining: 5m 12s\n",
            "71180:\tlearn: 0.9929567\ttest: 0.8764061\tbest: 0.8767146 (43570)\ttotal: 12m 52s\tremaining: 5m 12s\n",
            "71181:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71182:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71183:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71184:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71185:\tlearn: 0.9929567\ttest: 0.8764048\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71186:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71187:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71188:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71189:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71190:\tlearn: 0.9929569\ttest: 0.8764032\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71191:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71192:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71193:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71194:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71195:\tlearn: 0.9929570\ttest: 0.8764044\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71196:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71197:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71198:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71199:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71200:\tlearn: 0.9929580\ttest: 0.8764071\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71201:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71202:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71203:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71204:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71205:\tlearn: 0.9929591\ttest: 0.8764181\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71206:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71207:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71208:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71209:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71210:\tlearn: 0.9929591\ttest: 0.8764182\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71211:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71212:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71213:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71214:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71215:\tlearn: 0.9929591\ttest: 0.8764180\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71216:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71217:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71218:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71219:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71220:\tlearn: 0.9929591\ttest: 0.8764178\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71221:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71222:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71223:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71224:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71225:\tlearn: 0.9929591\ttest: 0.8764175\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71226:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71227:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71228:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71229:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71230:\tlearn: 0.9929592\ttest: 0.8764177\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71231:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71232:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71233:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71234:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71235:\tlearn: 0.9929601\ttest: 0.8764217\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71236:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71237:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71238:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71239:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71240:\tlearn: 0.9929603\ttest: 0.8764229\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71241:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71242:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71243:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71244:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71245:\tlearn: 0.9929603\ttest: 0.8764225\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71246:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71247:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71248:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71249:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71250:\tlearn: 0.9929603\ttest: 0.8764226\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71251:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71252:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71253:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71254:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71255:\tlearn: 0.9929603\ttest: 0.8764225\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71256:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71257:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71258:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71259:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71260:\tlearn: 0.9929609\ttest: 0.8764290\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71261:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71262:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71263:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71264:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71265:\tlearn: 0.9929632\ttest: 0.8764368\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71266:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71267:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71268:\ttotal: 12m 53s\tremaining: 5m 12s\n",
            "71269:\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71270:\tlearn: 0.9929632\ttest: 0.8764375\tbest: 0.8767146 (43570)\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71271:\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71272:\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71273:\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71274:\ttotal: 12m 53s\tremaining: 5m 11s\n",
            "71275:\tlearn: 0.9929637\ttest: 0.8764363\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71276:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71277:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71278:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71279:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71280:\tlearn: 0.9929637\ttest: 0.8764362\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71281:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71282:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71283:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71284:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71285:\tlearn: 0.9929638\ttest: 0.8764368\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71286:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71287:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71288:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71289:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71290:\tlearn: 0.9929638\ttest: 0.8764368\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71291:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71292:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71293:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71294:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71295:\tlearn: 0.9929638\ttest: 0.8764366\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71296:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71297:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71298:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71299:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71300:\tlearn: 0.9929654\ttest: 0.8764379\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71301:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71302:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71303:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71304:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71305:\tlearn: 0.9929655\ttest: 0.8764404\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71306:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71307:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71308:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71309:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71310:\tlearn: 0.9929655\ttest: 0.8764403\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71311:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71312:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71313:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71314:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71315:\tlearn: 0.9929655\ttest: 0.8764407\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71316:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71317:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71318:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71319:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71320:\tlearn: 0.9929656\ttest: 0.8764416\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71321:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71322:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71323:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71324:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71325:\tlearn: 0.9929656\ttest: 0.8764420\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71326:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71327:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71328:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71329:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71330:\tlearn: 0.9929661\ttest: 0.8764404\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71331:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71332:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71333:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71334:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71335:\tlearn: 0.9929661\ttest: 0.8764383\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71336:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71337:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71338:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71339:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71340:\tlearn: 0.9929662\ttest: 0.8764375\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71341:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71342:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71343:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71344:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71345:\tlearn: 0.9929662\ttest: 0.8764374\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71346:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71347:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71348:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71349:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71350:\tlearn: 0.9929663\ttest: 0.8764373\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71351:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71352:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71353:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71354:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71355:\tlearn: 0.9929666\ttest: 0.8764377\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71356:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71357:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71358:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71359:\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71360:\tlearn: 0.9929666\ttest: 0.8764372\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 11s\n",
            "71361:\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71362:\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71363:\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71364:\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71365:\tlearn: 0.9929670\ttest: 0.8764384\tbest: 0.8767146 (43570)\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71366:\ttotal: 12m 54s\tremaining: 5m 10s\n",
            "71367:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71368:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71369:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71370:\tlearn: 0.9929672\ttest: 0.8764366\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71371:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71372:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71373:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71374:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71375:\tlearn: 0.9929672\ttest: 0.8764363\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71376:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71377:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71378:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71379:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71380:\tlearn: 0.9929673\ttest: 0.8764351\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71381:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71382:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71383:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71384:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71385:\tlearn: 0.9929681\ttest: 0.8764321\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71386:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71387:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71388:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71389:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71390:\tlearn: 0.9929681\ttest: 0.8764321\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71391:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71392:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71393:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71394:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71395:\tlearn: 0.9929681\ttest: 0.8764321\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71396:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71397:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71398:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71399:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71400:\tlearn: 0.9929681\ttest: 0.8764314\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71401:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71402:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71403:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71404:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71405:\tlearn: 0.9929682\ttest: 0.8764315\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71406:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71407:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71408:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71409:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71410:\tlearn: 0.9929682\ttest: 0.8764322\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71411:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71412:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71413:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71414:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71415:\tlearn: 0.9929682\ttest: 0.8764327\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71416:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71417:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71418:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71419:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71420:\tlearn: 0.9929684\ttest: 0.8764316\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71421:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71422:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71423:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71424:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71425:\tlearn: 0.9929684\ttest: 0.8764318\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71426:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71427:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71428:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71429:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71430:\tlearn: 0.9929685\ttest: 0.8764313\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71431:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71432:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71433:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71434:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71435:\tlearn: 0.9929688\ttest: 0.8764313\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71436:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71437:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71438:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71439:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71440:\tlearn: 0.9929688\ttest: 0.8764313\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71441:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71442:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71443:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71444:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71445:\tlearn: 0.9929691\ttest: 0.8764287\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71446:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71447:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71448:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71449:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71450:\tlearn: 0.9929691\ttest: 0.8764293\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71451:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71452:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71453:\ttotal: 12m 55s\tremaining: 5m 10s\n",
            "71454:\ttotal: 12m 55s\tremaining: 5m 9s\n",
            "71455:\tlearn: 0.9929695\ttest: 0.8764296\tbest: 0.8767146 (43570)\ttotal: 12m 55s\tremaining: 5m 9s\n",
            "71456:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71457:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71458:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71459:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71460:\tlearn: 0.9929695\ttest: 0.8764295\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71461:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71462:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71463:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71464:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71465:\tlearn: 0.9929695\ttest: 0.8764291\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71466:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71467:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71468:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71469:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71470:\tlearn: 0.9929696\ttest: 0.8764287\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71471:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71472:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71473:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71474:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71475:\tlearn: 0.9929698\ttest: 0.8764301\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71476:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71477:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71478:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71479:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71480:\tlearn: 0.9929698\ttest: 0.8764301\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71481:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71482:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71483:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71484:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71485:\tlearn: 0.9929698\ttest: 0.8764297\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71486:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71487:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71488:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71489:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71490:\tlearn: 0.9929732\ttest: 0.8764141\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71491:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71492:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71493:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71494:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71495:\tlearn: 0.9929732\ttest: 0.8764141\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71496:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71497:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71498:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71499:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71500:\tlearn: 0.9929738\ttest: 0.8764142\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71501:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71502:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71503:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71504:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71505:\tlearn: 0.9929740\ttest: 0.8764167\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71506:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71507:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71508:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71509:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71510:\tlearn: 0.9929743\ttest: 0.8764196\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71511:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71512:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71513:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71514:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71515:\tlearn: 0.9929747\ttest: 0.8764189\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71516:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71517:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71518:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71519:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71520:\tlearn: 0.9929747\ttest: 0.8764187\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71521:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71522:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71523:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71524:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71525:\tlearn: 0.9929747\ttest: 0.8764194\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71526:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71527:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71528:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71529:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71530:\tlearn: 0.9929748\ttest: 0.8764195\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71531:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71532:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71533:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71534:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71535:\tlearn: 0.9929748\ttest: 0.8764196\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71536:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71537:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71538:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71539:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71540:\tlearn: 0.9929752\ttest: 0.8764193\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71541:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71542:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71543:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71544:\ttotal: 12m 56s\tremaining: 5m 9s\n",
            "71545:\tlearn: 0.9929752\ttest: 0.8764193\tbest: 0.8767146 (43570)\ttotal: 12m 56s\tremaining: 5m 8s\n",
            "71546:\ttotal: 12m 56s\tremaining: 5m 8s\n",
            "71547:\ttotal: 12m 56s\tremaining: 5m 8s\n",
            "71548:\ttotal: 12m 56s\tremaining: 5m 8s\n",
            "71549:\ttotal: 12m 56s\tremaining: 5m 8s\n",
            "71550:\tlearn: 0.9929783\ttest: 0.8764062\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71551:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71552:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71553:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71554:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71555:\tlearn: 0.9929793\ttest: 0.8764055\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71556:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71557:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71558:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71559:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71560:\tlearn: 0.9929797\ttest: 0.8764039\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71561:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71562:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71563:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71564:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71565:\tlearn: 0.9929797\ttest: 0.8764039\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71566:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71567:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71568:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71569:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71570:\tlearn: 0.9929797\ttest: 0.8764034\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71571:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71572:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71573:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71574:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71575:\tlearn: 0.9929798\ttest: 0.8764036\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71576:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71577:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71578:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71579:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71580:\tlearn: 0.9929803\ttest: 0.8764035\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71581:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71582:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71583:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71584:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71585:\tlearn: 0.9929809\ttest: 0.8764064\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71586:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71587:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71588:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71589:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71590:\tlearn: 0.9929810\ttest: 0.8764036\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71591:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71592:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71593:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71594:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71595:\tlearn: 0.9929811\ttest: 0.8764023\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71596:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71597:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71598:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71599:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71600:\tlearn: 0.9929811\ttest: 0.8764023\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71601:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71602:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71603:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71604:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71605:\tlearn: 0.9929811\ttest: 0.8764023\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71606:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71607:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71608:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71609:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71610:\tlearn: 0.9929818\ttest: 0.8764043\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71611:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71612:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71613:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71614:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71615:\tlearn: 0.9929818\ttest: 0.8764043\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71616:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71617:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71618:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71619:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71620:\tlearn: 0.9929825\ttest: 0.8764050\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71621:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71622:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71623:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71624:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71625:\tlearn: 0.9929826\ttest: 0.8764049\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71626:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71627:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71628:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71629:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71630:\tlearn: 0.9929826\ttest: 0.8764042\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71631:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71632:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71633:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71634:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71635:\tlearn: 0.9929826\ttest: 0.8764039\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71636:\ttotal: 12m 57s\tremaining: 5m 8s\n",
            "71637:\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71638:\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71639:\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71640:\tlearn: 0.9929842\ttest: 0.8764006\tbest: 0.8767146 (43570)\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71641:\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71642:\ttotal: 12m 57s\tremaining: 5m 7s\n",
            "71643:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71644:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71645:\tlearn: 0.9929843\ttest: 0.8763999\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71646:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71647:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71648:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71649:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71650:\tlearn: 0.9929845\ttest: 0.8763989\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71651:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71652:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71653:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71654:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71655:\tlearn: 0.9929845\ttest: 0.8763987\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71656:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71657:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71658:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71659:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71660:\tlearn: 0.9929845\ttest: 0.8763998\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71661:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71662:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71663:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71664:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71665:\tlearn: 0.9929848\ttest: 0.8763998\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71666:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71667:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71668:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71669:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71670:\tlearn: 0.9929849\ttest: 0.8763984\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71671:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71672:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71673:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71674:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71675:\tlearn: 0.9929850\ttest: 0.8763993\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71676:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71677:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71678:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71679:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71680:\tlearn: 0.9929851\ttest: 0.8764001\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71681:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71682:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71683:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71684:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71685:\tlearn: 0.9929862\ttest: 0.8763968\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71686:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71687:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71688:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71689:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71690:\tlearn: 0.9929862\ttest: 0.8763968\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71691:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71692:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71693:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71694:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71695:\tlearn: 0.9929864\ttest: 0.8763971\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71696:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71697:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71698:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71699:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71700:\tlearn: 0.9929865\ttest: 0.8763949\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71701:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71702:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71703:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71704:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71705:\tlearn: 0.9929865\ttest: 0.8763932\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71706:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71707:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71708:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71709:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71710:\tlearn: 0.9929866\ttest: 0.8763938\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71711:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71712:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71713:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71714:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71715:\tlearn: 0.9929866\ttest: 0.8763937\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71716:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71717:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71718:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71719:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71720:\tlearn: 0.9929866\ttest: 0.8763934\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71721:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71722:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71723:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71724:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71725:\tlearn: 0.9929866\ttest: 0.8763935\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71726:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71727:\ttotal: 12m 58s\tremaining: 5m 7s\n",
            "71728:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71729:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71730:\tlearn: 0.9929866\ttest: 0.8763935\tbest: 0.8767146 (43570)\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71731:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71732:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71733:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71734:\ttotal: 12m 58s\tremaining: 5m 6s\n",
            "71735:\tlearn: 0.9929868\ttest: 0.8763908\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71736:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71737:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71738:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71739:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71740:\tlearn: 0.9929868\ttest: 0.8763907\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71741:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71742:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71743:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71744:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71745:\tlearn: 0.9929870\ttest: 0.8763901\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71746:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71747:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71748:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71749:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71750:\tlearn: 0.9929876\ttest: 0.8763834\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71751:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71752:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71753:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71754:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71755:\tlearn: 0.9929876\ttest: 0.8763832\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71756:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71757:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71758:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71759:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71760:\tlearn: 0.9929876\ttest: 0.8763830\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71761:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71762:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71763:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71764:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71765:\tlearn: 0.9929876\ttest: 0.8763831\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71766:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71767:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71768:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71769:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71770:\tlearn: 0.9929877\ttest: 0.8763814\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71771:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71772:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71773:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71774:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71775:\tlearn: 0.9929878\ttest: 0.8763822\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71776:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71777:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71778:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71779:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71780:\tlearn: 0.9929878\ttest: 0.8763824\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71781:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71782:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71783:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71784:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71785:\tlearn: 0.9929888\ttest: 0.8763810\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71786:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71787:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71788:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71789:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71790:\tlearn: 0.9929893\ttest: 0.8763832\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71791:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71792:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71793:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71794:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71795:\tlearn: 0.9929893\ttest: 0.8763834\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71796:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71797:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71798:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71799:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71800:\tlearn: 0.9929915\ttest: 0.8763837\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71801:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71802:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71803:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71804:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71805:\tlearn: 0.9929929\ttest: 0.8763795\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71806:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71807:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71808:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71809:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71810:\tlearn: 0.9929934\ttest: 0.8763789\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71811:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71812:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71813:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71814:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71815:\tlearn: 0.9929948\ttest: 0.8763794\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71816:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71817:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71818:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71819:\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71820:\tlearn: 0.9929956\ttest: 0.8763829\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 6s\n",
            "71821:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71822:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71823:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71824:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71825:\tlearn: 0.9929956\ttest: 0.8763828\tbest: 0.8767146 (43570)\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71826:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71827:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71828:\ttotal: 12m 59s\tremaining: 5m 5s\n",
            "71829:\ttotal: 13m\tremaining: 5m 5s\n",
            "71830:\tlearn: 0.9929956\ttest: 0.8763829\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71831:\ttotal: 13m\tremaining: 5m 5s\n",
            "71832:\ttotal: 13m\tremaining: 5m 5s\n",
            "71833:\ttotal: 13m\tremaining: 5m 5s\n",
            "71834:\ttotal: 13m\tremaining: 5m 5s\n",
            "71835:\tlearn: 0.9929956\ttest: 0.8763818\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71836:\ttotal: 13m\tremaining: 5m 5s\n",
            "71837:\ttotal: 13m\tremaining: 5m 5s\n",
            "71838:\ttotal: 13m\tremaining: 5m 5s\n",
            "71839:\ttotal: 13m\tremaining: 5m 5s\n",
            "71840:\tlearn: 0.9929957\ttest: 0.8763796\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71841:\ttotal: 13m\tremaining: 5m 5s\n",
            "71842:\ttotal: 13m\tremaining: 5m 5s\n",
            "71843:\ttotal: 13m\tremaining: 5m 5s\n",
            "71844:\ttotal: 13m\tremaining: 5m 5s\n",
            "71845:\tlearn: 0.9929960\ttest: 0.8763764\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71846:\ttotal: 13m\tremaining: 5m 5s\n",
            "71847:\ttotal: 13m\tremaining: 5m 5s\n",
            "71848:\ttotal: 13m\tremaining: 5m 5s\n",
            "71849:\ttotal: 13m\tremaining: 5m 5s\n",
            "71850:\tlearn: 0.9929969\ttest: 0.8763744\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71851:\ttotal: 13m\tremaining: 5m 5s\n",
            "71852:\ttotal: 13m\tremaining: 5m 5s\n",
            "71853:\ttotal: 13m\tremaining: 5m 5s\n",
            "71854:\ttotal: 13m\tremaining: 5m 5s\n",
            "71855:\tlearn: 0.9929969\ttest: 0.8763739\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71856:\ttotal: 13m\tremaining: 5m 5s\n",
            "71857:\ttotal: 13m\tremaining: 5m 5s\n",
            "71858:\ttotal: 13m\tremaining: 5m 5s\n",
            "71859:\ttotal: 13m\tremaining: 5m 5s\n",
            "71860:\tlearn: 0.9929969\ttest: 0.8763743\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71861:\ttotal: 13m\tremaining: 5m 5s\n",
            "71862:\ttotal: 13m\tremaining: 5m 5s\n",
            "71863:\ttotal: 13m\tremaining: 5m 5s\n",
            "71864:\ttotal: 13m\tremaining: 5m 5s\n",
            "71865:\tlearn: 0.9929969\ttest: 0.8763752\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71866:\ttotal: 13m\tremaining: 5m 5s\n",
            "71867:\ttotal: 13m\tremaining: 5m 5s\n",
            "71868:\ttotal: 13m\tremaining: 5m 5s\n",
            "71869:\ttotal: 13m\tremaining: 5m 5s\n",
            "71870:\tlearn: 0.9929970\ttest: 0.8763747\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71871:\ttotal: 13m\tremaining: 5m 5s\n",
            "71872:\ttotal: 13m\tremaining: 5m 5s\n",
            "71873:\ttotal: 13m\tremaining: 5m 5s\n",
            "71874:\ttotal: 13m\tremaining: 5m 5s\n",
            "71875:\tlearn: 0.9929982\ttest: 0.8763730\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71876:\ttotal: 13m\tremaining: 5m 5s\n",
            "71877:\ttotal: 13m\tremaining: 5m 5s\n",
            "71878:\ttotal: 13m\tremaining: 5m 5s\n",
            "71879:\ttotal: 13m\tremaining: 5m 5s\n",
            "71880:\tlearn: 0.9929982\ttest: 0.8763710\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71881:\ttotal: 13m\tremaining: 5m 5s\n",
            "71882:\ttotal: 13m\tremaining: 5m 5s\n",
            "71883:\ttotal: 13m\tremaining: 5m 5s\n",
            "71884:\ttotal: 13m\tremaining: 5m 5s\n",
            "71885:\tlearn: 0.9929983\ttest: 0.8763719\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71886:\ttotal: 13m\tremaining: 5m 5s\n",
            "71887:\ttotal: 13m\tremaining: 5m 5s\n",
            "71888:\ttotal: 13m\tremaining: 5m 5s\n",
            "71889:\ttotal: 13m\tremaining: 5m 5s\n",
            "71890:\tlearn: 0.9929983\ttest: 0.8763723\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71891:\ttotal: 13m\tremaining: 5m 5s\n",
            "71892:\ttotal: 13m\tremaining: 5m 5s\n",
            "71893:\ttotal: 13m\tremaining: 5m 5s\n",
            "71894:\ttotal: 13m\tremaining: 5m 5s\n",
            "71895:\tlearn: 0.9929984\ttest: 0.8763718\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71896:\ttotal: 13m\tremaining: 5m 5s\n",
            "71897:\ttotal: 13m\tremaining: 5m 5s\n",
            "71898:\ttotal: 13m\tremaining: 5m 5s\n",
            "71899:\ttotal: 13m\tremaining: 5m 5s\n",
            "71900:\tlearn: 0.9929984\ttest: 0.8763717\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71901:\ttotal: 13m\tremaining: 5m 5s\n",
            "71902:\ttotal: 13m\tremaining: 5m 5s\n",
            "71903:\ttotal: 13m\tremaining: 5m 5s\n",
            "71904:\ttotal: 13m\tremaining: 5m 5s\n",
            "71905:\tlearn: 0.9929984\ttest: 0.8763717\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71906:\ttotal: 13m\tremaining: 5m 5s\n",
            "71907:\ttotal: 13m\tremaining: 5m 5s\n",
            "71908:\ttotal: 13m\tremaining: 5m 5s\n",
            "71909:\ttotal: 13m\tremaining: 5m 5s\n",
            "71910:\tlearn: 0.9929984\ttest: 0.8763716\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 5s\n",
            "71911:\ttotal: 13m\tremaining: 5m 5s\n",
            "71912:\ttotal: 13m\tremaining: 5m 4s\n",
            "71913:\ttotal: 13m\tremaining: 5m 4s\n",
            "71914:\ttotal: 13m\tremaining: 5m 4s\n",
            "71915:\tlearn: 0.9929984\ttest: 0.8763721\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 4s\n",
            "71916:\ttotal: 13m\tremaining: 5m 4s\n",
            "71917:\ttotal: 13m\tremaining: 5m 4s\n",
            "71918:\ttotal: 13m\tremaining: 5m 4s\n",
            "71919:\ttotal: 13m\tremaining: 5m 4s\n",
            "71920:\tlearn: 0.9929984\ttest: 0.8763723\tbest: 0.8767146 (43570)\ttotal: 13m\tremaining: 5m 4s\n",
            "71921:\ttotal: 13m\tremaining: 5m 4s\n",
            "71922:\ttotal: 13m\tremaining: 5m 4s\n",
            "71923:\ttotal: 13m\tremaining: 5m 4s\n",
            "71924:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71925:\tlearn: 0.9929986\ttest: 0.8763708\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71926:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71927:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71928:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71929:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71930:\tlearn: 0.9929990\ttest: 0.8763676\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71931:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71932:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71933:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71934:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71935:\tlearn: 0.9929991\ttest: 0.8763671\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71936:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71937:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71938:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71939:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71940:\tlearn: 0.9929991\ttest: 0.8763669\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71941:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71942:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71943:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71944:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71945:\tlearn: 0.9929993\ttest: 0.8763634\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71946:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71947:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71948:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71949:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71950:\tlearn: 0.9929994\ttest: 0.8763636\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71951:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71952:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71953:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71954:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71955:\tlearn: 0.9929994\ttest: 0.8763635\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71956:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71957:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71958:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71959:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71960:\tlearn: 0.9929995\ttest: 0.8763648\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71961:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71962:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71963:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71964:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71965:\tlearn: 0.9929995\ttest: 0.8763645\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71966:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71967:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71968:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71969:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71970:\tlearn: 0.9929995\ttest: 0.8763633\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71971:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71972:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71973:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71974:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71975:\tlearn: 0.9929996\ttest: 0.8763632\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71976:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71977:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71978:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71979:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71980:\tlearn: 0.9929996\ttest: 0.8763627\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71981:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71982:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71983:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71984:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71985:\tlearn: 0.9929998\ttest: 0.8763580\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71986:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71987:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71988:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71989:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71990:\tlearn: 0.9929999\ttest: 0.8763579\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71991:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71992:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71993:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71994:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71995:\tlearn: 0.9929999\ttest: 0.8763573\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71996:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71997:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71998:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "71999:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "72000:\tlearn: 0.9930009\ttest: 0.8763566\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "72001:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "72002:\ttotal: 13m 1s\tremaining: 5m 4s\n",
            "72003:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72004:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72005:\tlearn: 0.9930009\ttest: 0.8763574\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72006:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72007:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72008:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72009:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72010:\tlearn: 0.9930009\ttest: 0.8763567\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72011:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72012:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72013:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72014:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72015:\tlearn: 0.9930009\ttest: 0.8763567\tbest: 0.8767146 (43570)\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72016:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72017:\ttotal: 13m 1s\tremaining: 5m 3s\n",
            "72018:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72019:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72020:\tlearn: 0.9930009\ttest: 0.8763567\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72021:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72022:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72023:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72024:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72025:\tlearn: 0.9930009\ttest: 0.8763565\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72026:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72027:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72028:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72029:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72030:\tlearn: 0.9930010\ttest: 0.8763569\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72031:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72032:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72033:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72034:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72035:\tlearn: 0.9930014\ttest: 0.8763550\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72036:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72037:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72038:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72039:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72040:\tlearn: 0.9930014\ttest: 0.8763550\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72041:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72042:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72043:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72044:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72045:\tlearn: 0.9930023\ttest: 0.8763558\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72046:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72047:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72048:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72049:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72050:\tlearn: 0.9930023\ttest: 0.8763561\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72051:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72052:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72053:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72054:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72055:\tlearn: 0.9930025\ttest: 0.8763565\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72056:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72057:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72058:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72059:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72060:\tlearn: 0.9930032\ttest: 0.8763560\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72061:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72062:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72063:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72064:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72065:\tlearn: 0.9930032\ttest: 0.8763559\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72066:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72067:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72068:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72069:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72070:\tlearn: 0.9930032\ttest: 0.8763569\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72071:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72072:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72073:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72074:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72075:\tlearn: 0.9930033\ttest: 0.8763565\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72076:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72077:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72078:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72079:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72080:\tlearn: 0.9930033\ttest: 0.8763564\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72081:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72082:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72083:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72084:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72085:\tlearn: 0.9930033\ttest: 0.8763563\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72086:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72087:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72088:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72089:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72090:\tlearn: 0.9930033\ttest: 0.8763556\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72091:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72092:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72093:\ttotal: 13m 2s\tremaining: 5m 3s\n",
            "72094:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72095:\tlearn: 0.9930033\ttest: 0.8763555\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72096:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72097:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72098:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72099:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72100:\tlearn: 0.9930042\ttest: 0.8763591\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72101:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72102:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72103:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72104:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72105:\tlearn: 0.9930042\ttest: 0.8763596\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72106:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72107:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72108:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72109:\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72110:\tlearn: 0.9930043\ttest: 0.8763573\tbest: 0.8767146 (43570)\ttotal: 13m 2s\tremaining: 5m 2s\n",
            "72111:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72112:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72113:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72114:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72115:\tlearn: 0.9930046\ttest: 0.8763594\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72116:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72117:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72118:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72119:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72120:\tlearn: 0.9930047\ttest: 0.8763594\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72121:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72122:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72123:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72124:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72125:\tlearn: 0.9930047\ttest: 0.8763593\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72126:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72127:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72128:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72129:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72130:\tlearn: 0.9930047\ttest: 0.8763595\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72131:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72132:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72133:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72134:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72135:\tlearn: 0.9930047\ttest: 0.8763596\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72136:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72137:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72138:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72139:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72140:\tlearn: 0.9930050\ttest: 0.8763592\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72141:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72142:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72143:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72144:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72145:\tlearn: 0.9930051\ttest: 0.8763592\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72146:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72147:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72148:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72149:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72150:\tlearn: 0.9930061\ttest: 0.8763658\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72151:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72152:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72153:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72154:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72155:\tlearn: 0.9930062\ttest: 0.8763654\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72156:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72157:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72158:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72159:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72160:\tlearn: 0.9930064\ttest: 0.8763615\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72161:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72162:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72163:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72164:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72165:\tlearn: 0.9930064\ttest: 0.8763608\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72166:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72167:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72168:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72169:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72170:\tlearn: 0.9930064\ttest: 0.8763606\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72171:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72172:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72173:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72174:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72175:\tlearn: 0.9930064\ttest: 0.8763607\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72176:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72177:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72178:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72179:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72180:\tlearn: 0.9930064\ttest: 0.8763607\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72181:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72182:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72183:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72184:\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72185:\tlearn: 0.9930065\ttest: 0.8763613\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 2s\n",
            "72186:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72187:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72188:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72189:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72190:\tlearn: 0.9930066\ttest: 0.8763610\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72191:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72192:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72193:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72194:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72195:\tlearn: 0.9930066\ttest: 0.8763609\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72196:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72197:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72198:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72199:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72200:\tlearn: 0.9930066\ttest: 0.8763611\tbest: 0.8767146 (43570)\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72201:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72202:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72203:\ttotal: 13m 3s\tremaining: 5m 1s\n",
            "72204:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72205:\tlearn: 0.9930067\ttest: 0.8763601\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72206:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72207:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72208:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72209:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72210:\tlearn: 0.9930068\ttest: 0.8763597\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72211:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72212:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72213:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72214:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72215:\tlearn: 0.9930068\ttest: 0.8763591\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72216:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72217:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72218:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72219:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72220:\tlearn: 0.9930068\ttest: 0.8763592\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72221:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72222:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72223:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72224:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72225:\tlearn: 0.9930091\ttest: 0.8763547\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72226:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72227:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72228:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72229:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72230:\tlearn: 0.9930091\ttest: 0.8763549\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72231:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72232:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72233:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72234:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72235:\tlearn: 0.9930092\ttest: 0.8763548\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72236:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72237:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72238:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72239:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72240:\tlearn: 0.9930092\ttest: 0.8763553\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72241:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72242:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72243:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72244:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72245:\tlearn: 0.9930092\ttest: 0.8763553\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72246:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72247:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72248:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72249:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72250:\tlearn: 0.9930092\ttest: 0.8763533\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72251:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72252:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72253:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72254:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72255:\tlearn: 0.9930092\ttest: 0.8763532\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72256:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72257:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72258:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72259:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72260:\tlearn: 0.9930092\ttest: 0.8763534\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72261:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72262:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72263:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72264:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72265:\tlearn: 0.9930095\ttest: 0.8763526\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72266:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72267:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72268:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72269:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72270:\tlearn: 0.9930095\ttest: 0.8763529\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72271:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72272:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72273:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72274:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72275:\tlearn: 0.9930095\ttest: 0.8763524\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72276:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72277:\ttotal: 13m 4s\tremaining: 5m 1s\n",
            "72278:\ttotal: 13m 4s\tremaining: 5m\n",
            "72279:\ttotal: 13m 4s\tremaining: 5m\n",
            "72280:\tlearn: 0.9930095\ttest: 0.8763523\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m\n",
            "72281:\ttotal: 13m 4s\tremaining: 5m\n",
            "72282:\ttotal: 13m 4s\tremaining: 5m\n",
            "72283:\ttotal: 13m 4s\tremaining: 5m\n",
            "72284:\ttotal: 13m 4s\tremaining: 5m\n",
            "72285:\tlearn: 0.9930095\ttest: 0.8763524\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m\n",
            "72286:\ttotal: 13m 4s\tremaining: 5m\n",
            "72287:\ttotal: 13m 4s\tremaining: 5m\n",
            "72288:\ttotal: 13m 4s\tremaining: 5m\n",
            "72289:\ttotal: 13m 4s\tremaining: 5m\n",
            "72290:\tlearn: 0.9930095\ttest: 0.8763524\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m\n",
            "72291:\ttotal: 13m 4s\tremaining: 5m\n",
            "72292:\ttotal: 13m 4s\tremaining: 5m\n",
            "72293:\ttotal: 13m 4s\tremaining: 5m\n",
            "72294:\ttotal: 13m 4s\tremaining: 5m\n",
            "72295:\tlearn: 0.9930110\ttest: 0.8763479\tbest: 0.8767146 (43570)\ttotal: 13m 4s\tremaining: 5m\n",
            "72296:\ttotal: 13m 4s\tremaining: 5m\n",
            "72297:\ttotal: 13m 4s\tremaining: 5m\n",
            "72298:\ttotal: 13m 5s\tremaining: 5m\n",
            "72299:\ttotal: 13m 5s\tremaining: 5m\n",
            "72300:\tlearn: 0.9930110\ttest: 0.8763474\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72301:\ttotal: 13m 5s\tremaining: 5m\n",
            "72302:\ttotal: 13m 5s\tremaining: 5m\n",
            "72303:\ttotal: 13m 5s\tremaining: 5m\n",
            "72304:\ttotal: 13m 5s\tremaining: 5m\n",
            "72305:\tlearn: 0.9930111\ttest: 0.8763452\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72306:\ttotal: 13m 5s\tremaining: 5m\n",
            "72307:\ttotal: 13m 5s\tremaining: 5m\n",
            "72308:\ttotal: 13m 5s\tremaining: 5m\n",
            "72309:\ttotal: 13m 5s\tremaining: 5m\n",
            "72310:\tlearn: 0.9930114\ttest: 0.8763433\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72311:\ttotal: 13m 5s\tremaining: 5m\n",
            "72312:\ttotal: 13m 5s\tremaining: 5m\n",
            "72313:\ttotal: 13m 5s\tremaining: 5m\n",
            "72314:\ttotal: 13m 5s\tremaining: 5m\n",
            "72315:\tlearn: 0.9930128\ttest: 0.8763537\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72316:\ttotal: 13m 5s\tremaining: 5m\n",
            "72317:\ttotal: 13m 5s\tremaining: 5m\n",
            "72318:\ttotal: 13m 5s\tremaining: 5m\n",
            "72319:\ttotal: 13m 5s\tremaining: 5m\n",
            "72320:\tlearn: 0.9930128\ttest: 0.8763537\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72321:\ttotal: 13m 5s\tremaining: 5m\n",
            "72322:\ttotal: 13m 5s\tremaining: 5m\n",
            "72323:\ttotal: 13m 5s\tremaining: 5m\n",
            "72324:\ttotal: 13m 5s\tremaining: 5m\n",
            "72325:\tlearn: 0.9930128\ttest: 0.8763535\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72326:\ttotal: 13m 5s\tremaining: 5m\n",
            "72327:\ttotal: 13m 5s\tremaining: 5m\n",
            "72328:\ttotal: 13m 5s\tremaining: 5m\n",
            "72329:\ttotal: 13m 5s\tremaining: 5m\n",
            "72330:\tlearn: 0.9930128\ttest: 0.8763535\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72331:\ttotal: 13m 5s\tremaining: 5m\n",
            "72332:\ttotal: 13m 5s\tremaining: 5m\n",
            "72333:\ttotal: 13m 5s\tremaining: 5m\n",
            "72334:\ttotal: 13m 5s\tremaining: 5m\n",
            "72335:\tlearn: 0.9930128\ttest: 0.8763536\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72336:\ttotal: 13m 5s\tremaining: 5m\n",
            "72337:\ttotal: 13m 5s\tremaining: 5m\n",
            "72338:\ttotal: 13m 5s\tremaining: 5m\n",
            "72339:\ttotal: 13m 5s\tremaining: 5m\n",
            "72340:\tlearn: 0.9930128\ttest: 0.8763535\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72341:\ttotal: 13m 5s\tremaining: 5m\n",
            "72342:\ttotal: 13m 5s\tremaining: 5m\n",
            "72343:\ttotal: 13m 5s\tremaining: 5m\n",
            "72344:\ttotal: 13m 5s\tremaining: 5m\n",
            "72345:\tlearn: 0.9930129\ttest: 0.8763528\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72346:\ttotal: 13m 5s\tremaining: 5m\n",
            "72347:\ttotal: 13m 5s\tremaining: 5m\n",
            "72348:\ttotal: 13m 5s\tremaining: 5m\n",
            "72349:\ttotal: 13m 5s\tremaining: 5m\n",
            "72350:\tlearn: 0.9930129\ttest: 0.8763528\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72351:\ttotal: 13m 5s\tremaining: 5m\n",
            "72352:\ttotal: 13m 5s\tremaining: 5m\n",
            "72353:\ttotal: 13m 5s\tremaining: 5m\n",
            "72354:\ttotal: 13m 5s\tremaining: 5m\n",
            "72355:\tlearn: 0.9930132\ttest: 0.8763551\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72356:\ttotal: 13m 5s\tremaining: 5m\n",
            "72357:\ttotal: 13m 5s\tremaining: 5m\n",
            "72358:\ttotal: 13m 5s\tremaining: 5m\n",
            "72359:\ttotal: 13m 5s\tremaining: 5m\n",
            "72360:\tlearn: 0.9930132\ttest: 0.8763550\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72361:\ttotal: 13m 5s\tremaining: 5m\n",
            "72362:\ttotal: 13m 5s\tremaining: 5m\n",
            "72363:\ttotal: 13m 5s\tremaining: 5m\n",
            "72364:\ttotal: 13m 5s\tremaining: 5m\n",
            "72365:\tlearn: 0.9930132\ttest: 0.8763546\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 5m\n",
            "72366:\ttotal: 13m 5s\tremaining: 5m\n",
            "72367:\ttotal: 13m 5s\tremaining: 5m\n",
            "72368:\ttotal: 13m 5s\tremaining: 5m\n",
            "72369:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72370:\tlearn: 0.9930132\ttest: 0.8763546\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72371:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72372:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72373:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72374:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72375:\tlearn: 0.9930132\ttest: 0.8763545\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72376:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72377:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72378:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72379:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72380:\tlearn: 0.9930133\ttest: 0.8763554\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72381:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72382:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72383:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72384:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72385:\tlearn: 0.9930157\ttest: 0.8763574\tbest: 0.8767146 (43570)\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72386:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72387:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72388:\ttotal: 13m 5s\tremaining: 4m 59s\n",
            "72389:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72390:\tlearn: 0.9930157\ttest: 0.8763565\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72391:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72392:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72393:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72394:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72395:\tlearn: 0.9930157\ttest: 0.8763566\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72396:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72397:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72398:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72399:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72400:\tlearn: 0.9930160\ttest: 0.8763574\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72401:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72402:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72403:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72404:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72405:\tlearn: 0.9930160\ttest: 0.8763565\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72406:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72407:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72408:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72409:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72410:\tlearn: 0.9930170\ttest: 0.8763572\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72411:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72412:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72413:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72414:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72415:\tlearn: 0.9930171\ttest: 0.8763569\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72416:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72417:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72418:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72419:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72420:\tlearn: 0.9930182\ttest: 0.8763618\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72421:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72422:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72423:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72424:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72425:\tlearn: 0.9930183\ttest: 0.8763614\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72426:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72427:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72428:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72429:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72430:\tlearn: 0.9930183\ttest: 0.8763611\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72431:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72432:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72433:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72434:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72435:\tlearn: 0.9930184\ttest: 0.8763606\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72436:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72437:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72438:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72439:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72440:\tlearn: 0.9930184\ttest: 0.8763604\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72441:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72442:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72443:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72444:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72445:\tlearn: 0.9930184\ttest: 0.8763599\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72446:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72447:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72448:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72449:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72450:\tlearn: 0.9930186\ttest: 0.8763574\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72451:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72452:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72453:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72454:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72455:\tlearn: 0.9930187\ttest: 0.8763570\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72456:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72457:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72458:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72459:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72460:\tlearn: 0.9930190\ttest: 0.8763570\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72461:\ttotal: 13m 6s\tremaining: 4m 59s\n",
            "72462:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72463:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72464:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72465:\tlearn: 0.9930191\ttest: 0.8763562\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72466:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72467:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72468:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72469:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72470:\tlearn: 0.9930205\ttest: 0.8763556\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72471:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72472:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72473:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72474:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72475:\tlearn: 0.9930206\ttest: 0.8763554\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72476:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72477:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72478:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72479:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72480:\tlearn: 0.9930213\ttest: 0.8763515\tbest: 0.8767146 (43570)\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72481:\ttotal: 13m 6s\tremaining: 4m 58s\n",
            "72482:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72483:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72484:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72485:\tlearn: 0.9930213\ttest: 0.8763515\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72486:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72487:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72488:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72489:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72490:\tlearn: 0.9930214\ttest: 0.8763512\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72491:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72492:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72493:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72494:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72495:\tlearn: 0.9930215\ttest: 0.8763514\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72496:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72497:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72498:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72499:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72500:\tlearn: 0.9930219\ttest: 0.8763475\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72501:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72502:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72503:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72504:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72505:\tlearn: 0.9930220\ttest: 0.8763478\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72506:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72507:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72508:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72509:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72510:\tlearn: 0.9930220\ttest: 0.8763477\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72511:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72512:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72513:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72514:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72515:\tlearn: 0.9930221\ttest: 0.8763489\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72516:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72517:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72518:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72519:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72520:\tlearn: 0.9930250\ttest: 0.8763581\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72521:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72522:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72523:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72524:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72525:\tlearn: 0.9930251\ttest: 0.8763594\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72526:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72527:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72528:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72529:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72530:\tlearn: 0.9930251\ttest: 0.8763594\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72531:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72532:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72533:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72534:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72535:\tlearn: 0.9930251\ttest: 0.8763594\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72536:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72537:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72538:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72539:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72540:\tlearn: 0.9930251\ttest: 0.8763596\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72541:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72542:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72543:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72544:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72545:\tlearn: 0.9930252\ttest: 0.8763577\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72546:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72547:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72548:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72549:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72550:\tlearn: 0.9930253\ttest: 0.8763570\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72551:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72552:\ttotal: 13m 7s\tremaining: 4m 58s\n",
            "72553:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72554:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72555:\tlearn: 0.9930253\ttest: 0.8763570\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72556:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72557:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72558:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72559:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72560:\tlearn: 0.9930256\ttest: 0.8763560\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72561:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72562:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72563:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72564:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72565:\tlearn: 0.9930258\ttest: 0.8763554\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72566:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72567:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72568:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72569:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72570:\tlearn: 0.9930259\ttest: 0.8763542\tbest: 0.8767146 (43570)\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72571:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72572:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72573:\ttotal: 13m 7s\tremaining: 4m 57s\n",
            "72574:\ttotal: 13m 7s\tremaining: 4m 57s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-59679c593bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'R2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5728\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5730\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5731\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5732\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2356\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnlZu-8l7O22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost.sklearn import XGBRegressor\n",
        "best_model = XGBRegressor()\n",
        "# best_model.fit(X_train , y_train)\n",
        "# y_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "_va0FGI_isRM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqNju2eshosV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBT2954Ihonk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVkqsmYehohd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H2LBP__xhocE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdc6_xzMhoWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "977RCutg6M5x"
      },
      "outputs": [],
      "source": [
        "import umap.umap_ as umap\n",
        "reducer = umap.UMAP(n_components = 10)\n",
        "embedding = reducer.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fyqNy8P8GI07"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(embedding, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0kTtrf2I3q6",
        "outputId": "adab9c9b-f0f6-43b3-d16f-0cbbaade7133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:59:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ],
      "source": [
        "from xgboost.sklearn import XGBRegressor\n",
        "best_model = XGBRegressor()\n",
        "best_model.fit(X_train , y_train)\n",
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuNDGz9fLAJP",
        "outputId": "fbed3d01-1ca7-47fb-9543-f6e443df0ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6026230050497328"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "r2_score(y_pred , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op0FA5pCJk0A"
      },
      "outputs": [],
      "source": [
        "data_test_true = pd.DataFrame(X_test)\n",
        "data_test_pred = pd.DataFrame(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTC60SQAJk44"
      },
      "outputs": [],
      "source": [
        "data_test_true['Price'] = y_test\n",
        "data_test_pred['Price'] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja9g1PVnJlAA"
      },
      "outputs": [],
      "source": [
        "inverserd_data_true = scaler.inverse_transform(data_test_true)\n",
        "inverserd_data_pred = scaler.inverse_transform(data_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK7hrUGDKngm"
      },
      "outputs": [],
      "source": [
        "pd.Dataframe(inverserd_data_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgWs2x5eJlEs"
      },
      "outputs": [],
      "source": [
        "y_test = inverserd_data_true[:,265]\n",
        "y_pred = inverserd_data_pred[:,265]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAmNXKkHJlHn"
      },
      "outputs": [],
      "source": [
        "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlx9lKjFD4F6"
      },
      "outputs": [],
      "source": [
        "r2_score(y_test ,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmhWfy50MIOC"
      },
      "outputs": [],
      "source": [
        "#importing the necessary libraries \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "  \n",
        "#loading the dataset \n",
        "data = pd.read_csv('dataset.csv') \n",
        "  \n",
        "#separating the independent and dependent variables \n",
        "X = data.iloc[:, :-1].values  #independent variables \n",
        "y = data.iloc[:, -1].values   #dependent variable (target)  \n",
        "  \n",
        "#handling missing values with mean imputation  \n",
        "from sklearn.impute import SimpleImputer    #for missing values in numerical columns  \n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')    #creating an object of SimpleImputer class    #fitting the imputer object to our dataset  \n",
        "imputer = imputer.fit(X[:, :])     #replacing missing values with mean of respective column    X[:, :] = imputer.transform(X[:, :])     #handling categorical data with label encoding    le = LabelEncoder()     #converting all categorical columns into numerical columns    X[:, 4] = le.fit_transform(X[:, 4])      #one hot encoding for multi-categorical columns    ohe = OneHotEncoder(categorical_features=[4])     X = ohe.fit_transform(X).toarray()      #splitting the dataset into training and testing sets    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)      #building a random forest classifier model    model = RandomForestClassifier()     model.fit(X_train, y_train)      #predicting on test set and calculating accuracy score    ypreds = model.predict(X_test)     print(\"Accuracy Score:\", accuracy_score(ytest, ypreds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXwzP6VH4A4s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "#read in the dataset \n",
        "df = pd.read_csv('my_dataset.csv') \n",
        "\n",
        "#create new features by combining existing columns \n",
        "df['new_feature1'] = df['col1'] + df['col2'] \n",
        "df['new_feature2'] = df['col3'] * df['col4'] \n",
        "df['new_feature3'] = np.sqrt(df['col5']) \n",
        "df['new_feature4'] = np.log(df['col6']) \n",
        "\n",
        "#save the new dataset with the new features included \n",
        "df.to_csv('my_dataset_with_features.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxoRj/YI3jj6wpzajsDmyx",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}